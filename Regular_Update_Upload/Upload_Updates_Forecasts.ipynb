{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb588012",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<table>\n",
    "    <center>\n",
    "            <img src=\"https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/snowflake.png\">\n",
    "    </center>\n",
    "        <td>\n",
    "            <img src=\"../Images/logo.jpg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"../Images/call_center.jpg\" width=\"300\">\n",
    "        </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a62d7c",
   "metadata": {},
   "source": [
    "# Call Database to Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689ad9d",
   "metadata": {},
   "source": [
    "### Make sure you are running numpy 1.18.5\n",
    "Tensorflow and Keras will throw an error with numpy otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b543a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Make sure you are in the right conda env\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2d8524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfab721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## If you are having problems with the conda env:\n",
    "## Execute these in the terminal, respond with 'y' when prompted\n",
    "# !conda install keras\n",
    "# !conda install seaborn\n",
    "# !pip install -U numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip\n",
    "# !pip install -r https://raw.githubusercontent.com/snowflakedb/snowflake-connector-python/v2.4.6/tested_requirements/requirements_36.reqs\n",
    "# !pip install snowflake-connector-python\n",
    "# !pip install snowflake-connector-python[pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486de60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure to pip the connector and install the dependencies:\n",
    "# https://docs.snowflake.com/en/user-guide/python-connector-install.html\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from datetime import timedelta\n",
    "\n",
    "try:\n",
    "    f = open(\"../Login_Credentials/SF_Account_Info.txt\", \"r\")\n",
    "except:\n",
    "    f = open(\"..\\Login_Credentials\\SF_Account_Info.txt\", \"r\")\n",
    "    \n",
    "usr = f.readline()\n",
    "usr = usr.replace('\\n', '')\n",
    "psswrd = f.readline()\n",
    "psswrd = psswrd.replace('\\n', '')\n",
    "accnt = f.readline()\n",
    "accnt = accnt.replace('\\n', '')\n",
    "dbName = f.readline()\n",
    "dbName = dbName.replace('\\n', '')\n",
    "path = f.readline()\n",
    "path = path.replace('\\n', '')\n",
    "file1 = f.readline()\n",
    "file1 = file1.replace('\\n', '')\n",
    "file2 = f.readline()\n",
    "file2 = file2.replace('\\n', '')\n",
    "file3 = f.readline()\n",
    "file3 = file3.replace('\\n', '')\n",
    "file4 = f.readline()\n",
    "file4 = file4.replace('\\n', '')\n",
    "file5 = f.readline()\n",
    "file5 = file5.replace('\\n', '')\n",
    "file6 = f.readline()\n",
    "file6 = file6.replace('\\n', '')\n",
    "file7 = f.readline()\n",
    "file7 = file7.replace('\\n', '')\n",
    "file8 = f.readline()\n",
    "file8 = file8.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d58352",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(usr,'\\n', psswrd,'\\n', accnt,'\\n', dbName, '\\n', \n",
    "          path, '\\n', file1,'\\n', file2,'\\n', file3, '\\n', \n",
    "          file4,'\\n', file5,'\\n', file6,'\\n', file7,'\\n', file8)\n",
    "except:\n",
    "    print('Check Login_Credentials/README.md for more info.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ba0c02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    f1 = open(\"../Login_Credentials/SHARED_SF_Account_Info.txt\", \"r\")\n",
    "except:\n",
    "    f1 = open(\"..\\Login_Credentials\\SHARED_SF_Account_Info.txt\", \"r\")\n",
    "    \n",
    "shareName = f1.readline()\n",
    "shareName = shareName.replace('\\n', '')\n",
    "\n",
    "sharedAccnt1 = f1.readline()\n",
    "sharedAccnt1 = sharedAccnt1.replace('\\n', '')\n",
    "sharedAccnt2 = f1.readline()\n",
    "sharedAccnt2 = sharedAccnt2.replace('\\n', '')\n",
    "sharedAccnt3 = f1.readline()\n",
    "sharedAccnt3 = sharedAccnt3.replace('\\n', '')\n",
    "sharedAccnt4 = f1.readline()\n",
    "sharedAccnt4 = sharedAccnt4.replace('\\n', '')\n",
    "sharedAccnt5 = f1.readline()\n",
    "sharedAccnt5 = sharedAccnt5.replace('\\n', '')\n",
    "sharedAccnt6 = f1.readline()\n",
    "sharedAccnt6 = sharedAccnt6.replace('\\n', '')\n",
    "sharedAccnt7 = f1.readline()\n",
    "sharedAccnt7 = sharedAccnt7.replace('\\n', '')\n",
    "sharedAccnt8 = f1.readline()\n",
    "sharedAccnt8 = sharedAccnt8.replace('\\n', '')\n",
    "sharedAccnt9 = f1.readline()\n",
    "sharedAccnt9 = sharedAccnt9.replace('\\n', '')\n",
    "sharedAccnt10 = f1.readline()\n",
    "sharedAccnt10 = sharedAccnt10.replace('\\n', '')\n",
    "sharedAccnt11 = f1.readline()\n",
    "sharedAccnt11 = sharedAccnt11.replace('\\n', '')\n",
    "sharedAccnt12 = f1.readline()\n",
    "sharedAccnt12 = sharedAccnt12.replace('\\n', '')\n",
    "sharedAccnt13 = f1.readline()\n",
    "sharedAccnt13 = sharedAccnt13.replace('\\n', '')\n",
    "sharedAccnt14 = f1.readline()\n",
    "sharedAccnt14 = sharedAccnt14.replace('\\n', '')\n",
    "sharedAccnt15 = f1.readline()\n",
    "sharedAccnt15 = sharedAccnt15.replace('\\n', '')\n",
    "\n",
    "try:\n",
    "    print(f'The Following Share Will Be Created If It Does Not Exist: {shareName}\\n' \n",
    "          + 'The Following Accounts Will Be Granted Share Access:\\n'\n",
    "          + sharedAccnt1, sharedAccnt2, sharedAccnt3, sharedAccnt4,\n",
    "          sharedAccnt5, sharedAccnt6, sharedAccnt7, sharedAccnt8, \n",
    "          sharedAccnt9, sharedAccnt10, sharedAccnt11, sharedAccnt12,\n",
    "          sharedAccnt13, sharedAccnt14, sharedAccnt15)\n",
    "except:\n",
    "    print('Check Login_Credentials/README.md for more info.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001a68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accountList = [sharedAccnt1, sharedAccnt2, sharedAccnt3, sharedAccnt4, sharedAccnt5,\n",
    "               sharedAccnt6, sharedAccnt7, sharedAccnt8, sharedAccnt9, sharedAccnt10,\n",
    "               sharedAccnt11, sharedAccnt12, sharedAccnt13, sharedAccnt14, sharedAccnt15]\n",
    "ACCOUNT_LIST = []\n",
    "for i in accountList:\n",
    "    if len(i) != 0:\n",
    "        ACCOUNT_LIST.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc0031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aSQLstatement = 'USE database {};'.format(dbName)\n",
    "sqlScript = 'create share {};'.format(shareName)\n",
    "sqlScript1 = 'grant usage on database {} to share {};'.format(dbName, shareName)\n",
    "sqlScript2 = 'grant usage on schema {}.public to share {};'.format(dbName, shareName)\n",
    "sqlScript3 = 'grant select on all tables in schema {}.public to share {};'.format(dbName, shareName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a750f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to SF\n",
    "conn = snowflake.connector.connect(\n",
    "    user=usr,\n",
    "    password=psswrd,\n",
    "    account=accnt,\n",
    "    role='ACCOUNTADMIN',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    #database='<SOME_DATABASE>',\n",
    "    #table='<SOME_TABLE>',\n",
    "    #schema='PUBLIC'\n",
    "                                    )\n",
    "print(\"Connected to Snowflake using \" + usr + \" \" + accnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c931a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(path)\n",
    "print(\"\\tUsing files from dir \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b839ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadExcel(fileName):\n",
    "    # Returns Year of File Passed to Method\n",
    "    def fileYear():\n",
    "        aYear = fileName[-7:-5]\n",
    "        return '20' + aYear\n",
    "    \n",
    "    # Creates String to Pass to SF Python Connector for Table Creation\n",
    "    def moreFormat(theInput):\n",
    "        \n",
    "        anthrList = []\n",
    "        stringList = []\n",
    "        o = 0\n",
    "        \n",
    "        for i in theInput:\n",
    "            if i.startswith(' '):\n",
    "                theInput[o] = i.strip()\n",
    "            o = o + 1\n",
    "            \n",
    "            if len(i) > 255:\n",
    "                i = i[:255]\n",
    "        \n",
    "            splChar = [\n",
    "            '(',')','[',']','/','\\\\','-','.',':','\\t','<','>','\"','?',\n",
    "            '!','`',\"'\",'&','^',' ','{','}','+','=','~','|',';','%','#']\n",
    "            for x in splChar:\n",
    "                i = i.replace(x, '_')\n",
    "            anthrList.append(i)\n",
    "            stringList.append(i)\n",
    "\n",
    "        stringList = str(stringList)\n",
    "        stringList = stringList.replace(\"'\", '\"')\n",
    "        stringList = stringList.replace(\",\", ' varchar,\\n')\n",
    "        stringList = stringList.strip(\"[]\")\n",
    "        stringList = stringList + \" varchar\"\n",
    "\n",
    "        return anthrList, stringList\n",
    "    \n",
    "    # Convert to Pandas DF\n",
    "    def makePandas():\n",
    "        if fileName != '':\n",
    "            dfSheet1 = pd.read_excel(fileName, sheet_name=0)\n",
    "            dfSheet2 = pd.read_excel(fileName, sheet_name=1)\n",
    "            dfSheet3 = pd.read_excel(fileName, sheet_name=2)\n",
    "            dfSheet1.convert_dtypes(), dfSheet2.convert_dtypes(), dfSheet3.convert_dtypes()\n",
    "            \n",
    "            # Call moreFormat to pass string to SF Python Connector & Change DF Column Names to Match\n",
    "            thisVar1 = dfSheet1.columns.tolist()\n",
    "            dfSheet1.columns, stringList1 = moreFormat(thisVar1)\n",
    "            thisVar2 = dfSheet2.columns.tolist()\n",
    "            dfSheet2.columns, stringList2 = moreFormat(thisVar2)\n",
    "            thisVar3 = dfSheet3.columns.tolist()\n",
    "            dfSheet3.columns, stringList3 = moreFormat(thisVar3)\n",
    "            \n",
    "            # Create Cursor Object\n",
    "            conn.cursor().execute(\"CREATE DATABASE IF NOT EXISTS {}\".format(dbName.upper()))\n",
    "            conn.cursor().execute(\"USE DATABASE {}\".format(dbName.upper()))\n",
    "            \n",
    "            # Create Snowflake Table and Columns & Upload the DF to SF\n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"NEEDSMETANDUNMET{}({})\".format(fileYear(), stringList1))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet1, 'NEEDSMETANDUNMET{}'.format(fileYear()))\n",
    "            \n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"CALLREPORTS{}({})\".format(fileYear(), stringList2))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet2, 'CALLREPORTS{}'.format(fileYear()))\n",
    "            \n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"REFERRALS{}({})\".format(fileYear(), stringList3))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet3, 'REFERRALS{}'.format(fileYear()))            \n",
    "             \n",
    "            return print(fileName + ' Uploaded Succesfully To Snowflake!')\n",
    "        else:\n",
    "            return print('Nothing More to Upload.')\n",
    "    return makePandas()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Uploading \" + file8 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2fb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2021 Data File Provided in SF_Account_Info.txt have been uploaded now.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459bbbf",
   "metadata": {},
   "source": [
    "## SQL to be Executed on Snowflake\n",
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e59e1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# -- SPECIFICIES CORRECT SNOWFLAKE SETTINGS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript4 = 'USE role ACCOUNTADMIN;'\n",
    "sqlScript5 = 'USE warehouse COMPUTE_WH;'\n",
    "sqlScript6 = 'USE database \"{}\";'.format(dbName)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE AND ADDS ALL YEARS DATA TO IT\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"TOTAL_NEEDSMETANDUNMET\"\n",
    "sqlScript7 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\" SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2021\" WHERE \"NEEDSMETANDUNMET2021\".\"DateOfCall\" NOT IN (SELECT \"DateOfCall\" FROM \"TOTAL_NEEDSMETANDUNMET\");'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE AND ADDS ALL YEARS DATA TO IT\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"ADBNAMEHERE\".\"PUBLIC\".\"TOTAL_CALLREPORTS\"\n",
    "sqlScript15 = 'INSERT INTO \"TOTAL_CALLREPORTS\" SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2021\" WHERE \"CALLREPORTS2021\".\"DateOfCall\" NOT IN (SELECT \"DateOfCall\" FROM \"TOTAL_CALLREPORTS\");'\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE FROM TOTAL_* TABLES 13 COLUMNS TOTAL\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"TOTAL_SATURNCLOUD\" \n",
    "sqlScript23 = 'CREATE TABLE \"TOTAL_SATURNCLOUD\" AS SELECT \"TOTAL_NEEDSMETANDUNMET\".\"DateOfCall\", \"TOTAL_NEEDSMETANDUNMET\".\"CallReportNum\", \"TOTAL_NEEDSMETANDUNMET\".\"TaxonomyCode\", \"TOTAL_NEEDSMETANDUNMET\".\"TaxonomyName\", \"TOTAL_NEEDSMETANDUNMET\".\"StateProvince\", \"TOTAL_CALLREPORTS\".\"Demographics___Gender__Person_in_Need_\", \"TOTAL_CALLREPORTS\".\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"ADBNAMEHERE\".\"PUBLIC\".\"TOTAL_NEEDSMETANDUNMET\" INNER JOIN \"TOTAL_CALLREPORTS\" ON \"TOTAL_NEEDSMETANDUNMET\".\"CallReportNum\"=\"TOTAL_CALLREPORTS\".\"CallReportNum\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL NON CA VALUES FROM STATEPROVINCE AND THEN DROPS THE COL\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript24 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"StateProvince\" IS NULL;'\n",
    "sqlScript25 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"StateProvince\"!=\\'CA\\';'\n",
    "sqlScript26 = 'ALTER TABLE \"TOTAL_SATURNCLOUD\" DROP COLUMN \"StateProvince\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL REMAINING NULL VALUES FROM THE REST OF THE COLUMNS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript27 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"Demographics___Gender__Person_in_Need_\" IS NULL;'\n",
    "sqlScript28 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" IS NULL;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL DUPLICATE ROWS WITH SAME CALLREPORTNUM AND TAXONOMY CODE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript29 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"TaxonomyCode\" NOT LIKE \\'R%\\';'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL DUPLICATE ROWS WITH SAME CALLREPORTNUM AND TAXONOMY CODE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript30 = 'CREATE OR REPLACE TABLE \"TOTAL_SATURNCLOUD\" AS SELECT DISTINCT * FROM \"TOTAL_SATURNCLOUD\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CONSOLIDATE TAXONOMY CODES WITH * TAG\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript31 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"TaxonomyCode\" = LEFT(\"TaxonomyCode\", CHARINDEX(\\'*\\', \"TaxonomyCode\") - 2) WHERE CHARINDEX(\\'*\\', \"TaxonomyCode\") > 0;'\n",
    "sqlScript32 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"TaxonomyName\" = LEFT(\"TaxonomyName\", CHARINDEX(\\'*\\', \"TaxonomyName\") - 2) WHERE CHARINDEX(\\'*\\', \"TaxonomyName\") > 0;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- FORMAT DATEOFCALL TRUNCATE TIME\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript33 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"DateOfCall\" = LEFT(\"DateOfCall\", CHARINDEX(\\' \\', \"DateOfCall\") - 1) WHERE CHARINDEX(\\' \\', \"DateOfCall\") > 0;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- Demographics_Prior_or_Current_U_S_Military_Service_Person...\n",
    "# -- CHANGE ALL NON YES RESPONSES TO NO\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript34 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Unknown\\', \\'No\\');'\n",
    "sqlScript35 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Not Asked\\', \\'No\\');'\n",
    "sqlScript36 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Declined to Answer\\', \\'No\\');'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- Demographics_Gender_Person_in_Need CHANGE NOT ASKED, TRANS, AND\n",
    "# -- DECLINED TO ANSWER TO OTHER/UNKNOWN/CANNOT DETERMINE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript37 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Not Asked\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript38 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Declined to Answer\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript39 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Trans\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript40 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Client is person in need (not applicable)\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- COUNT CALLREPORT BY DATEOFCALL AND TAXONOMYNAME AND DEMOGRAPHICS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript41 = 'CREATE OR REPLACE TABLE \\\"TOTAL_SATURNCLOUD\\\" AS SELECT \\\"DateOfCall\\\", \\\"TaxonomyCode\\\", \\\"TaxonomyName\\\", \\\"Demographics___Gender__Person_in_Need_\\\", \\\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\\\", COUNT(*) AS \\\"NumberOfCalls\\\" FROM \\\"TOTAL_SATURNCLOUD\\\" GROUP BY \\\"DateOfCall\\\", \\\"TaxonomyCode\\\", \\\"TaxonomyName\\\", \\\"Demographics___Gender__Person_in_Need_\\\", \\\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\\\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CHANGE DATEOFCALL DATATYPE TO DATE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript42 = 'ALTER TABLE \"TOTAL_SATURNCLOUD\" ADD \\\"DATE\\\" DATE;'\n",
    "sqlScript43 = 'CREATE OR REPLACE TABLE \"TOTAL_SATURNCLOUD\" AS(SELECT to_date(\"DateOfCall\") date,\"NumberOfCalls\", \"TaxonomyCode\", \"TaxonomyName\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"TOTAL_SATURNCLOUD\");'\n",
    "sqlScript44 = 'alter table \"TOTAL_SATURNCLOUD\" rename column \"DATE\" to \"DateOfCall\";'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f994be7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sqlList = [sqlScript4 ,sqlScript5, sqlScript6, sqlScript7, \n",
    "           sqlScript15, sqlScript23, sqlScript24 ,sqlScript25 ,sqlScript25 ,\n",
    "           sqlScript26 ,sqlScript27, sqlScript28, sqlScript29,\n",
    "           sqlScript30, sqlScript31 ,sqlScript32 ,sqlScript33 ,\n",
    "           sqlScript34 ,sqlScript35, sqlScript36, sqlScript37,\n",
    "           sqlScript38, sqlScript39 ,sqlScript40 ,sqlScript41 ,\n",
    "           sqlScript42 ,sqlScript43, sqlScript44]\n",
    "# sqlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in sqlList:\n",
    "    try:\n",
    "        conn.cursor().execute(u)\n",
    "    except: \n",
    "        print(f'This SQL Query Could Not Be Executed:\\n{u}')\n",
    "        \n",
    "print('Preprocessing Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf6683",
   "metadata": {},
   "source": [
    "# Predictive Modeling & Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec4c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for t in sqlList[:3]:\n",
    "    try:\n",
    "        conn.cursor().execute(t)\n",
    "    except: \n",
    "        print(f'This SQL Query Could Not Be Executed:\\n{t}')\n",
    "        \n",
    "print('Snowflake Setup Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34d59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates dataframe frome Snowflake SQL Table\n",
    "curr = conn.cursor()\n",
    "sql = 'SELECT * FROM TOTAL_SATURNCLOUD'\n",
    "curr.execute(sql)\n",
    "\n",
    "df = curr.fetch_pandas_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd052b",
   "metadata": {},
   "source": [
    "### Renaming and dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6235446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'TaxonomyCode':'Level5Code',\n",
    "'Demographics___Gender__Person_in_Need_':'Gender',\n",
    "'Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_':'Militants'},inplace=True)\n",
    "\n",
    "df['Level2Code'] = df['Level5Code'].str.extract('(R.)', expand=True)\n",
    "\n",
    "df = df.drop(columns  = ['Level5Code','TaxonomyName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec923ca0",
   "metadata": {},
   "source": [
    "### Encoding Militants Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0343d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "## Militants - Categorical to Numerical\n",
    "taxonomy_encoded = le.fit_transform(df['Militants'])\n",
    "df['Militants'] = taxonomy_encoded\n",
    "\n",
    "df3 = pd.get_dummies(df,columns=['Level2Code','Gender'])\n",
    "\n",
    "df3 = df3.groupby(df3['DateOfCall'], as_index=False, sort=True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819d06e",
   "metadata": {},
   "source": [
    "### Basic number of unqiue values assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9cfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genderList = df['Gender'].unique()\n",
    "# for i in genderList:\n",
    "#     print(\"Number of \" + i + \" :\"+ str(len(df[df['Gender'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba68521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MilitantList = df['Militants'].unique()\n",
    "# for i in MilitantList:\n",
    "#     print(\"Number \" + str(i) + \" :\" + str(len(df[df['Militants'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e153a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8d673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Describe all the data\n",
    "# df3.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b800b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summarize missing by column\n",
    "# df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a0ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Separate dates for future plotting\n",
    "train_dates = pd.to_datetime(df3['DateOfCall'])\n",
    "\n",
    "## Variables for training\n",
    "df4 = df3.iloc[:, 1:11].astype(float)\n",
    "#df4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b5285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df4)\n",
    "df4_scaled = scaler.transform(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aee5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setting up a training/validation/testing dataset\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "n_future = 1 # Number of days we want to predict into the future\n",
    "n_past = 14 # Number of past days we want to use to predict the future\n",
    "\n",
    "for i in range (n_past, len(df4_scaled) - n_future +1):\n",
    "    X_train.append(df4_scaled[i - n_past:i, 0:df4.shape[1]])\n",
    "    y_train.append(df4_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "## Convert to numpy arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385af4ba",
   "metadata": {},
   "source": [
    "## Build a LSTM complex model with dropout, add L1 regularization, smaller weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44deb62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.regularizers import l1\n",
    "l1_penalty = 0.001\n",
    "\n",
    "# build a two layer neural network with regularization\n",
    "def build_model5():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   input_shape = (X_train.shape[1], X_train.shape[2]),\n",
    "                   return_sequences = True))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss = 'mse',\n",
    "                  metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "print('The model will take a few minutes to train.')\n",
    "# fit this model/architecture to my data\n",
    "history5 = build_model5()\n",
    "history5.fit(X_train,\n",
    "          y_train,\n",
    "          epochs = 500,\n",
    "          batch_size = 32,\n",
    "          validation_split = 0.2,\n",
    "          verbose = 0)\n",
    "print('Training completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf73a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#summarize model\n",
    "# history5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d7cb3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the loss function per epoch\n",
    "# plt.plot(history5.history.history['loss'],\n",
    "#          color='red')\n",
    "# plt.plot(history5.history.history['val_loss'],\n",
    "#          color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5154fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the loss function per epoch\n",
    "# plt.plot(history5.history.history['mae'],\n",
    "#          color='red')\n",
    "# plt.plot(history5.history.history['val_mae'],\n",
    "#          color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a58b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('The min validation loss of',\n",
    "#       np.min(history5.history.history['val_loss']),\n",
    "#       ',\\n was at epoch',\n",
    "#       np.argmin(history5.history.history['val_loss']))\n",
    "\n",
    "# print('The min validation mae of',\n",
    "#       np.min(history5.history.history['val_mae']),\n",
    "#       ',\\n was at epoch',\n",
    "#       np.argmin(history5.history.history['val_mae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d5f0f",
   "metadata": {},
   "source": [
    "## Forecasting Future Number Of Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70a8198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Begin with the next day in training and forcast future\n",
    "future_ndays = 30\n",
    "theVarName = list(train_dates)[-1]\n",
    "theVarName = theVarName + timedelta(days=1)\n",
    "\n",
    "forecast_period_dates = pd.date_range(theVarName, \n",
    "                                      periods = future_ndays, \n",
    "                                      freq = '1d').tolist()\n",
    "## forecast\n",
    "forecast = history5.predict(X_train[-future_ndays:])\n",
    "\n",
    "## Perform inverse transformation to rescale back to original range\n",
    "forecast_copies = np.repeat(forecast, \n",
    "                            df4.shape[1], \n",
    "                            axis = -1)\n",
    "y_pred_future = scaler.inverse_transform(forecast_copies)[:, 0]\n",
    "\n",
    "## Convert forecast timestamp to date\n",
    "forecast_dates = []\n",
    "for time_i in forecast_period_dates:\n",
    "    forecast_dates.append(time_i.date())\n",
    "\n",
    "df_forecast = pd.DataFrame({'DateOfCall': np.array(forecast_dates), \n",
    "                            'Forecast NumberOfCalls':y_pred_future})\n",
    "df_forecast['DateOfCall'] = pd.to_datetime(df_forecast['DateOfCall'])\n",
    "\n",
    "#df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c021c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b4ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original = df3[['DateOfCall', 'NumberOfCalls']]\n",
    "# Original['DateOfCall'] = pd.to_datetime(Original['DateOfCall'])\n",
    "# Original = Original.loc[Original['DateOfCall'] >= '2021-01-01']\n",
    "\n",
    "## Plot Observed and forecast\n",
    "# sns.lineplot(Original['DateOfCall'], Original['NumberOfCalls'])\n",
    "# sns.lineplot(df_forecast['DateOfCall'], df_forecast['Forecast NumberOfCalls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3d1e8",
   "metadata": {},
   "source": [
    "### Upload Predictions to Table In Same Snowflake Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f69242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures Column Names are in the Correct Format for Snowflake\n",
    "def moreFormat(theInput):\n",
    "        \n",
    "        anthrList = []\n",
    "        stringList = []\n",
    "        o = 0\n",
    "        \n",
    "        for i in theInput:\n",
    "            if i.startswith(' '):\n",
    "                theInput[o] = i.strip()\n",
    "            o = o + 1\n",
    "            \n",
    "            if len(i) > 255:\n",
    "                i = i[:255]\n",
    "        \n",
    "            splChar = [\n",
    "            '(',')','[',']','/','\\\\','-','.',':','\\t','<','>','\"','?',\n",
    "            '!','`',\"'\",'&','^',' ','{','}','+','=','~','|',';','%','#']\n",
    "            for x in splChar:\n",
    "                i = i.replace(x, '_')\n",
    "            anthrList.append(i)\n",
    "            stringList.append(i)\n",
    "\n",
    "        stringList = str(stringList)\n",
    "        stringList = stringList.replace(\"'\", '\"')\n",
    "        stringList = stringList.replace(\",\", ' varchar,\\n')\n",
    "        stringList = stringList.strip(\"[]\")\n",
    "        stringList = stringList + \" varchar\"\n",
    "\n",
    "        return anthrList, stringList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5882800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast.convert_dtypes()\n",
    "thisVar1 = df_forecast.columns.tolist()\n",
    "df_forecast.columns, stringList1 = moreFormat(thisVar1)\n",
    "\n",
    "# Snowflake not accepting pandas datetime datatype correctly\n",
    "df_forecast['DateOfCall'] = df_forecast['DateOfCall'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b0ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for Table Column Names and Datatypes\n",
    "stringList1 = '\"DateOfCall\" VARCHAR, \"Forecast_NumberOfCalls\" FLOAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4fe275",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.cursor().execute(\"USE DATABASE {}\".format(dbName.upper()))\n",
    "\n",
    "# try:\n",
    "#     conn.cursor().execute(\"DROP TABLE \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\"\")\n",
    "# except:\n",
    "#     continue\n",
    "    \n",
    "# Create Snowflake Table and Columns & Upload the DF to SF\n",
    "conn.cursor().execute(\n",
    "    \"CREATE OR REPLACE TABLE \"\n",
    "    \"TOTAL_SATURNCLOUD_PREDICTIONS({})\".format(stringList1))\n",
    "success, nchunks, nrows, _ = write_pandas(conn, df_forecast, 'TOTAL_SATURNCLOUD_PREDICTIONS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e72d4",
   "metadata": {},
   "source": [
    "#### Changes VARCHAR to DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.cursor().execute('ALTER TABLE \"TOTAL_SATURNCLOUD_PREDICTIONS\" ADD \"DATE\" DATE;')\n",
    "\n",
    "\n",
    "conn.cursor().execute(\n",
    "    'CREATE OR REPLACE TABLE \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\" AS(SELECT to_date(\\\"DateOfCall\\\") date,\\\"Forecast_NumberOfCalls\\\"FROM \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\");')\n",
    "\n",
    "conn.cursor().execute('alter table \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\" rename column \\\"DATE\\\" to \\\"DateOfCall\\\";')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a1426c-ac03-4003-8d46-a25adf683455",
   "metadata": {},
   "source": [
    "### Select the past 30 days data to be compared to the forecasted calls\n",
    "This is to make things smoother for PBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd12206b-136f-432b-adf0-21dbf39c43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.cursor().execute('ALTER TABLE \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\" ADD \\\"NumberOfCalls\\\" NUMBER(18,0);')\n",
    "conn.cursor().execute('INSERT INTO \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\"(\\\"DateOfCall\\\", \\\"NumberOfCalls\\\") SELECT \\\"DateOfCall\\\", SUM(\\\"NumberOfCalls\\\") FROM \\\"TOTAL_SATURNCLOUD\\\" GROUP BY \\\"DateOfCall\\\" ORDER BY \\\"DateOfCall\\\" DESC LIMIT 30;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf996931",
   "metadata": {},
   "source": [
    "## Sets Up Shares on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn.cursor().execute(aSQLstatement)\n",
    "    conn.cursor().execute(sqlScript)\n",
    "    print('Share Created!')\n",
    "except:\n",
    "    print(\"This share already esixts in your Snowflake account.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn.cursor().execute(aSQLstatement)\n",
    "    conn.cursor().execute(sqlScript1)\n",
    "    conn.cursor().execute(sqlScript2)\n",
    "    conn.cursor().execute(sqlScript3)\n",
    "except:\n",
    "    print(\"There was an error in the grant usage on... SQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf64266",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for x in ACCOUNT_LIST:\n",
    "        sqlScriptShare = 'alter share {} add accounts={};'.format(shareName, x)\n",
    "        conn.cursor().execute(aSQLstatement)\n",
    "        try:\n",
    "            conn.cursor().execute(sqlScriptShare)\n",
    "        except:\n",
    "            print('Account {} Could Not be Added.'.format(x))\n",
    "    print(\"Accounts Successfully Added to {}!\".format(shareName))\n",
    "except:\n",
    "    print(\"There was an error in the alter share {} add accounts=... SQL.\".format(shareName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda061d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.cursor().close()\n",
    "print(\"Connection to Snowflake has been closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07992763",
   "metadata": {},
   "source": [
    "## Check your Snowflake account to see if the Database & Table are created and filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b197e5d",
   "metadata": {},
   "source": [
    "## *IMPORTANT*: This only works with accounts that are from the same region and cloud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31087583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfca9907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Method\n",
    "# from snowflake.connector.pandas_tools import pd_writer\n",
    "\n",
    "\n",
    "# # Specify that the to_sql method should use the pd_writer function\n",
    "# # to write the data from the DataFrame to the table named \"customers\"\n",
    "# # in the Snowflake database.\n",
    "# dfTotal.to_sql('FORMATTED_REPORTS', conn, index=False, method=pd_writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
