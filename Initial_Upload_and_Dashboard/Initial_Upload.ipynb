{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb588012",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<table>\n",
    "    <center>\n",
    "            <img src=\"https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/snowflake.png\">\n",
    "    </center>\n",
    "        <td>\n",
    "            <img src=\"..\\Images\\logo.jpg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"..\\Images\\call_center.jpg\" width=\"300\">\n",
    "        </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a62d7c",
   "metadata": {},
   "source": [
    "# Call Database to Snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689ad9d",
   "metadata": {},
   "source": [
    "### Make sure you are running in a python 3.6 environment\n",
    "Tensorflow and Keras will throw an error with numpy otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638b543a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     C:\\ProgramData\\Anaconda3\n",
      "sfupload                 C:\\ProgramData\\Anaconda3\\envs\\sfupload\n",
      "snowflake             *  C:\\ProgramData\\Anaconda3\\envs\\snowflake\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Make sure you are in the right conda env\n",
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2d8524",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.8\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfab721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## If you are having problems with the conda env:\n",
    "## Execute these in the terminal, respond with 'y' when prompted\n",
    "# !conda install keras\n",
    "# !conda install seaborn\n",
    "# !pip install -U numpy==1.18.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d823a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install --upgrade pip\n",
    "# !pip install -r https://raw.githubusercontent.com/snowflakedb/snowflake-connector-python/v2.4.6/tested_requirements/requirements_36.reqs\n",
    "# !pip install snowflake-connector-python\n",
    "# !pip install snowflake-connector-python[pandas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486de60f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure to pip the connector and install the dependencies:\n",
    "# https://docs.snowflake.com/en/user-guide/python-connector-install.html\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "try:\n",
    "    f = open(\"../Login_Credentials/SF_Account_Info.txt\", \"r\")\n",
    "except:\n",
    "    f = open(\"..\\Login_Credentials\\SF_Account_Info.txt\", \"r\")\n",
    "    \n",
    "usr = f.readline()\n",
    "usr = usr.replace('\\n', '')\n",
    "psswrd = f.readline()\n",
    "psswrd = psswrd.replace('\\n', '')\n",
    "accnt = f.readline()\n",
    "accnt = accnt.replace('\\n', '')\n",
    "dbName = f.readline()\n",
    "dbName = dbName.replace('\\n', '')\n",
    "path = f.readline()\n",
    "path = path.replace('\\n', '')\n",
    "file1 = f.readline()\n",
    "file1 = file1.replace('\\n', '')\n",
    "file2 = f.readline()\n",
    "file2 = file2.replace('\\n', '')\n",
    "file3 = f.readline()\n",
    "file3 = file3.replace('\\n', '')\n",
    "file4 = f.readline()\n",
    "file4 = file4.replace('\\n', '')\n",
    "file5 = f.readline()\n",
    "file5 = file5.replace('\\n', '')\n",
    "file6 = f.readline()\n",
    "file6 = file6.replace('\\n', '')\n",
    "file7 = f.readline()\n",
    "file7 = file7.replace('\\n', '')\n",
    "file8 = f.readline()\n",
    "file8 = file8.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d58352",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCHARIPAR5 \n",
      " Victoria5! \n",
      " ob28888.east-us-2.azure \n",
      " ADBNAMEHERE \n",
      " J:\\\\Plan4Co\\SaturnCloud\\211-OC_Data\\ \n",
      " FormattedCallReports_year 2014.xlsx \n",
      " FormattedCallReports_year 2015.xlsx \n",
      " FormattedCallReports_year 2016.xlsx \n",
      " FormattedCallReports_year 2017.xlsx \n",
      " FormattedCallReports_year 2018.xlsx \n",
      " FormattedCallReports_year 2019.xlsx \n",
      " FormattedCallReports_year 2020.xlsx \n",
      " FormattedCallReports_year 2021.xlsx\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(usr,'\\n', psswrd,'\\n', accnt,'\\n', dbName, '\\n', \n",
    "          path, '\\n', file1,'\\n', file2,'\\n', file3, '\\n', \n",
    "          file4,'\\n', file5,'\\n', file6,'\\n', file7,'\\n', file8)\n",
    "except:\n",
    "    print('Check Login_Credentials/README.md for more info.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0ba0c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Following Share Will Be Created If It Does Not Exist: ashare\n",
      "The Following Accounts Will Be Granted Share Access:\n",
      "L000000 O000000 A000000 B000000 C000000 E000000 G000000 G000000 J000000 S000000 T000000 X000000 Z000000 Z000000 \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    f1 = open(\"../Login_Credentials/SHARED_SF_Account_Info.txt\", \"r\")\n",
    "except:\n",
    "    f1 = open(\"..\\Login_Credentials\\SHARED_SF_Account_Info.txt\", \"r\")\n",
    "    \n",
    "shareName = f1.readline()\n",
    "shareName = shareName.replace('\\n', '')\n",
    "\n",
    "sharedAccnt1 = f1.readline()\n",
    "sharedAccnt1 = sharedAccnt1.replace('\\n', '')\n",
    "sharedAccnt2 = f1.readline()\n",
    "sharedAccnt2 = sharedAccnt2.replace('\\n', '')\n",
    "sharedAccnt3 = f1.readline()\n",
    "sharedAccnt3 = sharedAccnt3.replace('\\n', '')\n",
    "sharedAccnt4 = f1.readline()\n",
    "sharedAccnt4 = sharedAccnt4.replace('\\n', '')\n",
    "sharedAccnt5 = f1.readline()\n",
    "sharedAccnt5 = sharedAccnt5.replace('\\n', '')\n",
    "sharedAccnt6 = f1.readline()\n",
    "sharedAccnt6 = sharedAccnt6.replace('\\n', '')\n",
    "sharedAccnt7 = f1.readline()\n",
    "sharedAccnt7 = sharedAccnt7.replace('\\n', '')\n",
    "sharedAccnt8 = f1.readline()\n",
    "sharedAccnt8 = sharedAccnt8.replace('\\n', '')\n",
    "sharedAccnt9 = f1.readline()\n",
    "sharedAccnt9 = sharedAccnt9.replace('\\n', '')\n",
    "sharedAccnt10 = f1.readline()\n",
    "sharedAccnt10 = sharedAccnt10.replace('\\n', '')\n",
    "sharedAccnt11 = f1.readline()\n",
    "sharedAccnt11 = sharedAccnt11.replace('\\n', '')\n",
    "sharedAccnt12 = f1.readline()\n",
    "sharedAccnt12 = sharedAccnt12.replace('\\n', '')\n",
    "sharedAccnt13 = f1.readline()\n",
    "sharedAccnt13 = sharedAccnt13.replace('\\n', '')\n",
    "sharedAccnt14 = f1.readline()\n",
    "sharedAccnt14 = sharedAccnt14.replace('\\n', '')\n",
    "sharedAccnt15 = f1.readline()\n",
    "sharedAccnt15 = sharedAccnt15.replace('\\n', '')\n",
    "\n",
    "try:\n",
    "    print(f'The Following Share Will Be Created If It Does Not Exist: {shareName}\\n' \n",
    "          + 'The Following Accounts Will Be Granted Share Access:\\n'\n",
    "          + sharedAccnt1, sharedAccnt2, sharedAccnt3, sharedAccnt4,\n",
    "          sharedAccnt5, sharedAccnt6, sharedAccnt7, sharedAccnt8, \n",
    "          sharedAccnt9, sharedAccnt10, sharedAccnt11, sharedAccnt12,\n",
    "          sharedAccnt13, sharedAccnt14, sharedAccnt15)\n",
    "except:\n",
    "    print('Check Login_Credentials/README.md for more info.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8001a68c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accountList = [sharedAccnt1, sharedAccnt2, sharedAccnt3, sharedAccnt4, sharedAccnt5,\n",
    "               sharedAccnt6, sharedAccnt7, sharedAccnt8, sharedAccnt9, sharedAccnt10,\n",
    "               sharedAccnt11, sharedAccnt12, sharedAccnt13, sharedAccnt14, sharedAccnt15]\n",
    "ACCOUNT_LIST = []\n",
    "for i in accountList:\n",
    "    if len(i) != 0:\n",
    "        ACCOUNT_LIST.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dcc0031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aSQLstatement = 'USE database {};'.format(dbName)\n",
    "sqlScript = 'create share {};'.format(shareName)\n",
    "sqlScript1 = 'grant usage on database {} to share {};'.format(dbName, shareName)\n",
    "sqlScript2 = 'grant usage on schema {}.public to share {};'.format(dbName, shareName)\n",
    "sqlScript3 = 'grant select on all tables in schema {}.public to share {};'.format(dbName, shareName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "116a750f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake using MCHARIPAR5 ob28888.east-us-2.azure\n"
     ]
    }
   ],
   "source": [
    "# Connect to SF\n",
    "conn = snowflake.connector.connect(\n",
    "    user=usr,\n",
    "    password=psswrd,\n",
    "    account=accnt,\n",
    "    role='ACCOUNTADMIN',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    #database='<SOME_DATABASE>',\n",
    "    #table='<SOME_TABLE>',\n",
    "    #schema='PUBLIC'\n",
    "                                    )\n",
    "print(\"Connected to Snowflake using \" + usr + \" \" + accnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "771c931a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing files from dir J:\\\\Plan4Co\\SaturnCloud\\211-OC_Data\\\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "print(\"\\tUsing files from dir \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b839ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadExcel(fileName):\n",
    "    # Returns Year of File Passed to Method\n",
    "    def fileYear():\n",
    "        aYear = fileName[-7:-5]\n",
    "        return '20' + aYear\n",
    "    \n",
    "    # Creates String to Pass to SF Python Connector for Table Creation\n",
    "    def moreFormat(theInput):\n",
    "        \n",
    "        anthrList = []\n",
    "        stringList = []\n",
    "        o = 0\n",
    "        \n",
    "        for i in theInput:\n",
    "            if i.startswith(' '):\n",
    "                theInput[o] = i.strip()\n",
    "            o = o + 1\n",
    "            \n",
    "            if len(i) > 255:\n",
    "                i = i[:255]\n",
    "        \n",
    "            splChar = [\n",
    "            '(',')','[',']','/','\\\\','-','.',':','\\t','<','>','\"','?',\n",
    "            '!','`',\"'\",'&','^',' ','{','}','+','=','~','|',';','%','#']\n",
    "            for x in splChar:\n",
    "                i = i.replace(x, '_')\n",
    "            anthrList.append(i)\n",
    "            stringList.append(i)\n",
    "\n",
    "        stringList = str(stringList)\n",
    "        stringList = stringList.replace(\"'\", '\"')\n",
    "        stringList = stringList.replace(\",\", ' varchar,\\n')\n",
    "        stringList = stringList.strip(\"[]\")\n",
    "        stringList = stringList + \" varchar\"\n",
    "\n",
    "        return anthrList, stringList\n",
    "    \n",
    "    # Convert to Pandas DF\n",
    "    def makePandas():\n",
    "        if fileName != '':\n",
    "            dfSheet1 = pd.read_excel(fileName, sheet_name=0)\n",
    "            dfSheet2 = pd.read_excel(fileName, sheet_name=1)\n",
    "            dfSheet3 = pd.read_excel(fileName, sheet_name=2)\n",
    "            dfSheet1.convert_dtypes(), dfSheet2.convert_dtypes(), dfSheet3.convert_dtypes()\n",
    "            \n",
    "            # Call moreFormat to pass string to SF Python Connector & Change DF Column Names to Match\n",
    "            thisVar1 = dfSheet1.columns.tolist()\n",
    "            dfSheet1.columns, stringList1 = moreFormat(thisVar1)\n",
    "            thisVar2 = dfSheet2.columns.tolist()\n",
    "            dfSheet2.columns, stringList2 = moreFormat(thisVar2)\n",
    "            thisVar3 = dfSheet3.columns.tolist()\n",
    "            dfSheet3.columns, stringList3 = moreFormat(thisVar3)\n",
    "            \n",
    "            # Create Cursor Object\n",
    "            conn.cursor().execute(\"CREATE DATABASE IF NOT EXISTS {}\".format(dbName.upper()))\n",
    "            conn.cursor().execute(\"USE DATABASE {}\".format(dbName.upper()))\n",
    "            \n",
    "            # Create Snowflake Table and Columns & Upload the DF to SF\n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"NEEDSMETANDUNMET{}({})\".format(fileYear(), stringList1))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet1, 'NEEDSMETANDUNMET{}'.format(fileYear()))\n",
    "            \n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"CALLREPORTS{}({})\".format(fileYear(), stringList2))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet2, 'CALLREPORTS{}'.format(fileYear()))\n",
    "            \n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"REFERRALS{}({})\".format(fileYear(), stringList3))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet3, 'REFERRALS{}'.format(fileYear()))            \n",
    "             \n",
    "            return print(fileName + ' Uploaded Succesfully To Snowflake!')\n",
    "        else:\n",
    "            return print('Nothing More to Upload.')\n",
    "    return makePandas()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56711c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2014.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2014.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file1 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6851823e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2015.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2015.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file2 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b0779d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2016.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2016.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file3 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfa7f85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2017.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2017.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file4 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8feb0ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2018.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2018.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file5 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13850d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2019.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2019.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file6 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13a378e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2020.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2020.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file7 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9fc486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2021.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2021.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file8 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a2fb3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Files Provided in SF_Account_Info.txt have been uploaded now.\n"
     ]
    }
   ],
   "source": [
    "print(\"All Files Provided in SF_Account_Info.txt have been uploaded now.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459bbbf",
   "metadata": {},
   "source": [
    "## SQL to be Executed on Snowflake\n",
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e59e1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# -- SPECIFICIES CORRECT SNOWFLAKE SETTINGS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript4 = 'USE role ACCOUNTADMIN;'\n",
    "sqlScript5 = 'USE warehouse COMPUTE_WH;'\n",
    "sqlScript6 = 'USE database \"{}\";'.format(dbName)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE AND ADDS ALL YEARS DATA TO IT\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"TOTAL_NEEDSMETANDUNMET\"\n",
    "sqlScript7 = 'CREATE TABLE \"TOTAL_NEEDSMETANDUNMET\" AS SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2014\";'\n",
    "sqlScript8 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2015\";'\n",
    "sqlScript9 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2016\";'\n",
    "sqlScript10 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2017\";'\n",
    "sqlScript11 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2018\";'\n",
    "sqlScript12 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2019\";'\n",
    "sqlScript13 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2020\";'\n",
    "sqlScript14 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2021\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE AND ADDS ALL YEARS DATA TO IT\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"ADBNAMEHERE\".\"PUBLIC\".\"TOTAL_CALLREPORTS\"\n",
    "sqlScript15 = 'CREATE TABLE \"TOTAL_CALLREPORTS\" AS SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2014\";'\n",
    "sqlScript16 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2015\";'\n",
    "sqlScript17 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2016\";'\n",
    "sqlScript18 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2017\";'\n",
    "sqlScript19 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2018\";'\n",
    "sqlScript20 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2019\";'\n",
    "sqlScript21 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2020\";'\n",
    "sqlScript22 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2021\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE FROM TOTAL_* TABLES 13 COLUMNS TOTAL\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"TOTAL_SATURNCLOUD\" \n",
    "sqlScript23 = 'CREATE TABLE \"TOTAL_SATURNCLOUD\" AS SELECT \"TOTAL_NEEDSMETANDUNMET\".\"DateOfCall\", \"TOTAL_NEEDSMETANDUNMET\".\"CallReportNum\", \"TOTAL_NEEDSMETANDUNMET\".\"TaxonomyCode\", \"TOTAL_NEEDSMETANDUNMET\".\"TaxonomyName\", \"TOTAL_NEEDSMETANDUNMET\".\"StateProvince\", \"TOTAL_CALLREPORTS\".\"Demographics___Gender__Person_in_Need_\", \"TOTAL_CALLREPORTS\".\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"ADBNAMEHERE\".\"PUBLIC\".\"TOTAL_NEEDSMETANDUNMET\" INNER JOIN \"TOTAL_CALLREPORTS\" ON \"TOTAL_NEEDSMETANDUNMET\".\"CallReportNum\"=\"TOTAL_CALLREPORTS\".\"CallReportNum\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL NON CA VALUES FROM STATEPROVINCE AND THEN DROPS THE COL\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript24 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"StateProvince\" IS NULL;'\n",
    "sqlScript25 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"StateProvince\"!=\\'CA\\';'\n",
    "sqlScript26 = 'ALTER TABLE \"TOTAL_SATURNCLOUD\" DROP COLUMN \"StateProvince\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL REMAINING NULL VALUES FROM THE REST OF THE COLUMNS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript27 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"Demographics___Gender__Person_in_Need_\" IS NULL;'\n",
    "sqlScript28 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" IS NULL;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL DUPLICATE ROWS WITH SAME CALLREPORTNUM AND TAXONOMY CODE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript29 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"TaxonomyCode\" NOT LIKE \\'R%\\';'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL DUPLICATE ROWS WITH SAME CALLREPORTNUM AND TAXONOMY CODE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript30 = 'CREATE OR REPLACE TABLE \"TOTAL_SATURNCLOUD\" AS SELECT DISTINCT * FROM \"TOTAL_SATURNCLOUD\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CONSOLIDATE TAXONOMY CODES WITH * TAG\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript31 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"TaxonomyCode\" = LEFT(\"TaxonomyCode\", CHARINDEX(\\'*\\', \"TaxonomyCode\") - 2) WHERE CHARINDEX(\\'*\\', \"TaxonomyCode\") > 0;'\n",
    "sqlScript32 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"TaxonomyName\" = LEFT(\"TaxonomyName\", CHARINDEX(\\'*\\', \"TaxonomyName\") - 2) WHERE CHARINDEX(\\'*\\', \"TaxonomyName\") > 0;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- FORMAT DATEOFCALL TRUNCATE TIME\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript33 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"DateOfCall\" = LEFT(\"DateOfCall\", CHARINDEX(\\' \\', \"DateOfCall\") - 1) WHERE CHARINDEX(\\' \\', \"DateOfCall\") > 0;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- Demographics_Prior_or_Current_U_S_Military_Service_Person...\n",
    "# -- CHANGE ALL NON YES RESPONSES TO NO\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript34 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Unknown\\', \\'No\\');'\n",
    "sqlScript35 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Not Asked\\', \\'No\\');'\n",
    "sqlScript36 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Declined to Answer\\', \\'No\\');'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- Demographics_Gender_Person_in_Need CHANGE NOT ASKED, TRANS, AND\n",
    "# -- DECLINED TO ANSWER TO OTHER/UNKNOWN/CANNOT DETERMINE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript37 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Not Asked\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript38 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Declined to Answer\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript39 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Trans\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript40 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Client is person in need (not applicable)\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- COUNT CALLREPORT BY DATEOFCALL AND TAXONOMYNAME AND DEMOGRAPHICS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript41 = 'CREATE OR REPLACE TABLE \\\"TOTAL_SATURNCLOUD\\\" AS SELECT \\\"DateOfCall\\\", \\\"TaxonomyCode\\\", \\\"TaxonomyName\\\", \\\"Demographics___Gender__Person_in_Need_\\\", \\\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\\\", COUNT(*) AS \\\"NumberOfCalls\\\" FROM \\\"TOTAL_SATURNCLOUD\\\" GROUP BY \\\"DateOfCall\\\", \\\"TaxonomyCode\\\", \\\"TaxonomyName\\\", \\\"Demographics___Gender__Person_in_Need_\\\", \\\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\\\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CHANGE DATEOFCALL DATATYPE TO DATE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript42 = 'ALTER TABLE \"TOTAL_SATURNCLOUD\" ADD \\\"DATE\\\" DATE;'\n",
    "sqlScript43 = 'CREATE OR REPLACE TABLE \"TOTAL_SATURNCLOUD\" AS(SELECT to_date(\"DateOfCall\") date,\"NumberOfCalls\", \"TaxonomyCode\", \"TaxonomyName\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"TOTAL_SATURNCLOUD\");'\n",
    "sqlScript44 = 'alter table \"TOTAL_SATURNCLOUD\" rename column \"DATE\" to \"DateOfCall\";'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f994be7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sqlList = [sqlScript4 ,sqlScript5, sqlScript6, sqlScript7, \n",
    "           sqlScript8, sqlScript9 ,sqlScript10 ,sqlScript11 ,\n",
    "           sqlScript12 ,sqlScript13, sqlScript14, sqlScript15,\n",
    "           sqlScript16, sqlScript16 ,sqlScript17 ,sqlScript18 ,\n",
    "           sqlScript19 ,sqlScript20, sqlScript21, sqlScript22,\n",
    "           sqlScript23, sqlScript24 ,sqlScript25 ,sqlScript25 ,\n",
    "           sqlScript26 ,sqlScript27, sqlScript28, sqlScript29,\n",
    "           sqlScript30, sqlScript31 ,sqlScript32 ,sqlScript33 ,\n",
    "           sqlScript34 ,sqlScript35, sqlScript36, sqlScript37,\n",
    "           sqlScript38, sqlScript39 ,sqlScript40 ,sqlScript41 ,\n",
    "           sqlScript42 ,sqlScript43, sqlScript44]\n",
    "# sqlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in sqlList:\n",
    "    try:\n",
    "        conn.cursor().execute(u)\n",
    "    except: \n",
    "        print(f'This SQL Query Could Not Be Executed:\\n{u}')\n",
    "        \n",
    "print('Preprocessing Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bf6683",
   "metadata": {},
   "source": [
    "# Predictive Modeling & Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46ec4c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Setup Complete\n"
     ]
    }
   ],
   "source": [
    "for t in sqlList[:3]:\n",
    "    try:\n",
    "        conn.cursor().execute(t)\n",
    "    except: \n",
    "        print(f'This SQL Query Could Not Be Executed:\\n{t}')\n",
    "        \n",
    "print('Snowflake Setup Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b34d59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates dataframe frome Snowflake SQL Table\n",
    "curr = conn.cursor()\n",
    "sql = 'SELECT * FROM TOTAL_SATURNCLOUD'\n",
    "curr.execute(sql)\n",
    "\n",
    "df = curr.fetch_pandas_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd052b",
   "metadata": {},
   "source": [
    "### Renaming and dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6235446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'TaxonomyCode':'Level5Code',\n",
    "'Demographics___Gender__Person_in_Need_':'Gender',\n",
    "'Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_':'Militants'},inplace=True)\n",
    "\n",
    "df['Level2Code'] = df['Level5Code'].str.extract('(R.)', expand=True)\n",
    "\n",
    "df = df.drop(columns  = ['Level5Code','TaxonomyName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec923ca0",
   "metadata": {},
   "source": [
    "### Encoding Militants Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc0343d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "## Militants - Categorical to Numerical\n",
    "taxonomy_encoded = le.fit_transform(df['Militants'])\n",
    "df['Militants'] = taxonomy_encoded\n",
    "\n",
    "df3 = pd.get_dummies(df,columns=['Level2Code','Gender'])\n",
    "\n",
    "df3 = df3.groupby(df3['DateOfCall'], as_index=False, sort=True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b819d06e",
   "metadata": {},
   "source": [
    "### Basic number of unqiue values assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36b9cfcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genderList = df['Gender'].unique()\n",
    "# for i in genderList:\n",
    "#     print(\"Number of \" + i + \" :\"+ str(len(df[df['Gender'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ba68521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MilitantList = df['Militants'].unique()\n",
    "# for i in MilitantList:\n",
    "#     print(\"Number \" + str(i) + \" :\" + str(len(df[df['Militants'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68e153a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fb8d673",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Describe all the data\n",
    "# df3.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a79b800b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# summarize missing by column\n",
    "# df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea3a0ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Separate dates for future plotting\n",
    "train_dates = pd.to_datetime(df3['DateOfCall'])\n",
    "\n",
    "## Variables for training\n",
    "df4 = df3.iloc[:, 1:11].astype(float)\n",
    "#df4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "582b5285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df4)\n",
    "df4_scaled = scaler.transform(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31aee5b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Setting up a training/validation/testing dataset\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "n_future = 1 # Number of days we want to predict into the future\n",
    "n_past = 14 # Number of past days we want to use to predict the future\n",
    "\n",
    "for i in range (n_past, len(df4_scaled) - n_future +1):\n",
    "    X_train.append(df4_scaled[i - n_past:i, 0:df4.shape[1]])\n",
    "    y_train.append(df4_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "## Convert to numpy arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385af4ba",
   "metadata": {},
   "source": [
    "## Build a LSTM complex model with dropout, add L1 regularization, smaller weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c44deb62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will take a few minutes to train.\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.regularizers import l1\n",
    "l1_penalty = 0.001\n",
    "\n",
    "# build a two layer neural network with regularization\n",
    "def build_model5():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   input_shape = (X_train.shape[1], X_train.shape[2]),\n",
    "                   return_sequences = True))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss = 'mse',\n",
    "                  metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "print('The model will take a few minutes to train.')\n",
    "# fit this model/architecture to my data\n",
    "history5 = build_model5()\n",
    "history5.fit(X_train,\n",
    "          y_train,\n",
    "          epochs = 500,\n",
    "          batch_size = 32,\n",
    "          validation_split = 0.2,\n",
    "          verbose = 0)\n",
    "print('Training completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecf73a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#summarize model\n",
    "# history5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d7cb3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the loss function per epoch\n",
    "# plt.plot(history5.history.history['loss'],\n",
    "#          color='red')\n",
    "# plt.plot(history5.history.history['val_loss'],\n",
    "#          color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5154fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot the loss function per epoch\n",
    "# plt.plot(history5.history.history['mae'],\n",
    "#          color='red')\n",
    "# plt.plot(history5.history.history['val_mae'],\n",
    "#          color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083a58b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('The min validation loss of',\n",
    "#       np.min(history5.history.history['val_loss']),\n",
    "#       ',\\n was at epoch',\n",
    "#       np.argmin(history5.history.history['val_loss']))\n",
    "\n",
    "# print('The min validation mae of',\n",
    "#       np.min(history5.history.history['val_mae']),\n",
    "#       ',\\n was at epoch',\n",
    "#       np.argmin(history5.history.history['val_mae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d5f0f",
   "metadata": {},
   "source": [
    "## Forecasting Future Number Of Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e70a8198",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Begin with the last day in training and forcast future\n",
    "future_ndays = 30\n",
    "\n",
    "#####################\n",
    "theVarName = list(train_dates)[-1] + 1\n",
    "############################################################\n",
    "forecast_period_dates = pd.date_range(theVarName, \n",
    "                                      periods = future_ndays, \n",
    "                                      freq = '1d').tolist()\n",
    "############################################################\n",
    "## forecast\n",
    "forecast = history5.predict(X_train[-future_ndays:])\n",
    "\n",
    "## Perform inverse transformation to rescale back to original range\n",
    "forecast_copies = np.repeat(forecast, \n",
    "                            df4.shape[1], \n",
    "                            axis = -1)\n",
    "y_pred_future = scaler.inverse_transform(forecast_copies)[:, 0]\n",
    "\n",
    "## Convert forecast timestamp to date\n",
    "forecast_dates = []\n",
    "for time_i in forecast_period_dates:\n",
    "    forecast_dates.append(time_i.date())\n",
    "\n",
    "df_forecast = pd.DataFrame({'DateOfCall': np.array(forecast_dates), \n",
    "                            'Forecast NumberOfCalls':y_pred_future})\n",
    "df_forecast['DateOfCall'] = pd.to_datetime(df_forecast['DateOfCall'])\n",
    "\n",
    "#df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "981c021c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfCall</th>\n",
       "      <th>Forecast NumberOfCalls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>34.100784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>23.454424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>23.127895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-09</td>\n",
       "      <td>22.535770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-10</td>\n",
       "      <td>21.775370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>9.186438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-07-12</td>\n",
       "      <td>22.909151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>21.878513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>18.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>20.282541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-07-16</td>\n",
       "      <td>19.840668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-07-17</td>\n",
       "      <td>13.911404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-07-18</td>\n",
       "      <td>13.659187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-07-19</td>\n",
       "      <td>18.545866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-07-20</td>\n",
       "      <td>32.080650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-07-21</td>\n",
       "      <td>32.573044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>24.969378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-07-23</td>\n",
       "      <td>19.356190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-07-24</td>\n",
       "      <td>15.101660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>10.769789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-07-26</td>\n",
       "      <td>9.545112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-07-27</td>\n",
       "      <td>19.731350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>24.277739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-07-29</td>\n",
       "      <td>19.081314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-07-30</td>\n",
       "      <td>18.548864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-07-31</td>\n",
       "      <td>14.087066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>13.524605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-08-02</td>\n",
       "      <td>13.442788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-08-03</td>\n",
       "      <td>32.426617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>29.391926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DateOfCall  Forecast NumberOfCalls\n",
       "0  2021-07-06               34.100784\n",
       "1  2021-07-07               23.454424\n",
       "2  2021-07-08               23.127895\n",
       "3  2021-07-09               22.535770\n",
       "4  2021-07-10               21.775370\n",
       "5  2021-07-11                9.186438\n",
       "6  2021-07-12               22.909151\n",
       "7  2021-07-13               21.878513\n",
       "8  2021-07-14               18.503090\n",
       "9  2021-07-15               20.282541\n",
       "10 2021-07-16               19.840668\n",
       "11 2021-07-17               13.911404\n",
       "12 2021-07-18               13.659187\n",
       "13 2021-07-19               18.545866\n",
       "14 2021-07-20               32.080650\n",
       "15 2021-07-21               32.573044\n",
       "16 2021-07-22               24.969378\n",
       "17 2021-07-23               19.356190\n",
       "18 2021-07-24               15.101660\n",
       "19 2021-07-25               10.769789\n",
       "20 2021-07-26                9.545112\n",
       "21 2021-07-27               19.731350\n",
       "22 2021-07-28               24.277739\n",
       "23 2021-07-29               19.081314\n",
       "24 2021-07-30               18.548864\n",
       "25 2021-07-31               14.087066\n",
       "26 2021-08-01               13.524605\n",
       "27 2021-08-02               13.442788\n",
       "28 2021-08-03               32.426617\n",
       "29 2021-08-04               29.391926"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72b4ae5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:42.588486Z",
     "iopub.status.busy": "2021-08-03T16:33:42.588209Z",
     "iopub.status.idle": "2021-08-03T16:33:42.591237Z",
     "shell.execute_reply": "2021-08-03T16:33:42.590585Z",
     "shell.execute_reply.started": "2021-08-03T16:33:42.588460Z"
    }
   },
   "outputs": [],
   "source": [
    "# Original = df3[['DateOfCall', 'NumberOfCalls']]\n",
    "# Original['DateOfCall'] = pd.to_datetime(Original['DateOfCall'])\n",
    "# Original = Original.loc[Original['DateOfCall'] >= '2021-01-01']\n",
    "\n",
    "## Plot Observed and forecast\n",
    "# sns.lineplot(Original['DateOfCall'], Original['NumberOfCalls'])\n",
    "# sns.lineplot(df_forecast['DateOfCall'], df_forecast['Forecast NumberOfCalls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b3d1e8",
   "metadata": {},
   "source": [
    "### Upload Predictions to Table In Same Snowflake Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7f69242a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:47.204672Z",
     "iopub.status.busy": "2021-08-03T16:33:47.204438Z",
     "iopub.status.idle": "2021-08-03T16:33:47.210395Z",
     "shell.execute_reply": "2021-08-03T16:33:47.209654Z",
     "shell.execute_reply.started": "2021-08-03T16:33:47.204649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ensures Column Names are in the Correct Format for Snowflake\n",
    "def moreFormat(theInput):\n",
    "        \n",
    "        anthrList = []\n",
    "        stringList = []\n",
    "        o = 0\n",
    "        \n",
    "        for i in theInput:\n",
    "            if i.startswith(' '):\n",
    "                theInput[o] = i.strip()\n",
    "            o = o + 1\n",
    "            \n",
    "            if len(i) > 255:\n",
    "                i = i[:255]\n",
    "        \n",
    "            splChar = [\n",
    "            '(',')','[',']','/','\\\\','-','.',':','\\t','<','>','\"','?',\n",
    "            '!','`',\"'\",'&','^',' ','{','}','+','=','~','|',';','%','#']\n",
    "            for x in splChar:\n",
    "                i = i.replace(x, '_')\n",
    "            anthrList.append(i)\n",
    "            stringList.append(i)\n",
    "\n",
    "        stringList = str(stringList)\n",
    "        stringList = stringList.replace(\"'\", '\"')\n",
    "        stringList = stringList.replace(\",\", ' varchar,\\n')\n",
    "        stringList = stringList.strip(\"[]\")\n",
    "        stringList = stringList + \" varchar\"\n",
    "\n",
    "        return anthrList, stringList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c5882800",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:48.971354Z",
     "iopub.status.busy": "2021-08-03T16:33:48.971120Z",
     "iopub.status.idle": "2021-08-03T16:33:48.975962Z",
     "shell.execute_reply": "2021-08-03T16:33:48.975259Z",
     "shell.execute_reply.started": "2021-08-03T16:33:48.971330Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_forecast.convert_dtypes()\n",
    "thisVar1 = df_forecast.columns.tolist()\n",
    "df_forecast.columns, stringList1 = moreFormat(thisVar1)\n",
    "\n",
    "# Snowflake not accepting pandas datetime datatype correctly\n",
    "df_forecast['DateOfCall'] = df_forecast['DateOfCall'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d935f3f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:49.938901Z",
     "iopub.status.busy": "2021-08-03T16:33:49.938664Z",
     "iopub.status.idle": "2021-08-03T16:33:49.941455Z",
     "shell.execute_reply": "2021-08-03T16:33:49.940881Z",
     "shell.execute_reply.started": "2021-08-03T16:33:49.938877Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_forecast.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "569b0ebd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:50.447180Z",
     "iopub.status.busy": "2021-08-03T16:33:50.446939Z",
     "iopub.status.idle": "2021-08-03T16:33:50.449832Z",
     "shell.execute_reply": "2021-08-03T16:33:50.449267Z",
     "shell.execute_reply.started": "2021-08-03T16:33:50.447155Z"
    }
   },
   "outputs": [],
   "source": [
    "# SQL for Table Column Names and Datatypes\n",
    "stringList1 = '\"DateOfCall\" VARCHAR, \"Forecast_NumberOfCalls\" FLOAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b4fe275",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:51.052292Z",
     "iopub.status.busy": "2021-08-03T16:33:51.051971Z",
     "iopub.status.idle": "2021-08-03T16:33:55.663914Z",
     "shell.execute_reply": "2021-08-03T16:33:55.663211Z",
     "shell.execute_reply.started": "2021-08-03T16:33:51.052254Z"
    }
   },
   "outputs": [],
   "source": [
    "conn.cursor().execute(\"USE DATABASE {}\".format(dbName.upper()))\n",
    "            \n",
    "# Create Snowflake Table and Columns & Upload the DF to SF\n",
    "conn.cursor().execute(\n",
    "    \"CREATE OR REPLACE TABLE \"\n",
    "    \"TOTAL_SATURNCLOUD_PREDICTIONS({})\".format(stringList1))\n",
    "success, nchunks, nrows, _ = write_pandas(conn, df_forecast, 'TOTAL_SATURNCLOUD_PREDICTIONS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864e72d4",
   "metadata": {},
   "source": [
    "#### Changes VARCHAR to DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fd34e12a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:55.665431Z",
     "iopub.status.busy": "2021-08-03T16:33:55.665251Z",
     "iopub.status.idle": "2021-08-03T16:33:57.737974Z",
     "shell.execute_reply": "2021-08-03T16:33:57.737386Z",
     "shell.execute_reply.started": "2021-08-03T16:33:55.665407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.connector.cursor.SnowflakeCursor at 0x7f271632e910>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.cursor().execute('ALTER TABLE \"TOTAL_SATURNCLOUD_PREDICTIONS\" ADD \"DATE\" DATE;')\n",
    "\n",
    "\n",
    "conn.cursor().execute(\n",
    "    'CREATE OR REPLACE TABLE \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\" AS(SELECT to_date(\\\"DateOfCall\\\") date,\\\"Forecast_NumberOfCalls\\\"FROM \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\");')\n",
    "\n",
    "conn.cursor().execute('alter table \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\" rename column \\\"DATE\\\" to \\\"DateOfCall\\\";')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf996931",
   "metadata": {},
   "source": [
    "## Sets Up Shares on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e4f492f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:57.739573Z",
     "iopub.status.busy": "2021-08-03T16:33:57.739318Z",
     "iopub.status.idle": "2021-08-03T16:33:57.992083Z",
     "shell.execute_reply": "2021-08-03T16:33:57.991392Z",
     "shell.execute_reply.started": "2021-08-03T16:33:57.739540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This share already esixts in your Snowflake account.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    conn.cursor().execute(aSQLstatement)\n",
    "    conn.cursor().execute(sqlScript)\n",
    "    print('Share Created!')\n",
    "except:\n",
    "    print(\"This share already esixts in your Snowflake account.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b81f21e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:33:57.993174Z",
     "iopub.status.busy": "2021-08-03T16:33:57.992984Z",
     "iopub.status.idle": "2021-08-03T16:33:58.719343Z",
     "shell.execute_reply": "2021-08-03T16:33:58.718727Z",
     "shell.execute_reply.started": "2021-08-03T16:33:57.993151Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    conn.cursor().execute(aSQLstatement)\n",
    "    conn.cursor().execute(sqlScript1)\n",
    "    conn.cursor().execute(sqlScript2)\n",
    "    conn.cursor().execute(sqlScript3)\n",
    "except:\n",
    "    print(\"There was an error in the grant usage on... SQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3bf64266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:34:01.741908Z",
     "iopub.status.busy": "2021-08-03T16:34:01.741667Z",
     "iopub.status.idle": "2021-08-03T16:34:05.596410Z",
     "shell.execute_reply": "2021-08-03T16:34:05.595770Z",
     "shell.execute_reply.started": "2021-08-03T16:34:01.741883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account L000000 Could Not be Added.\n",
      "Account O000000 Could Not be Added.\n",
      "Account A000000 Could Not be Added.\n",
      "Account B000000 Could Not be Added.\n",
      "Account C000000 Could Not be Added.\n",
      "Account E000000 Could Not be Added.\n",
      "Account G000000 Could Not be Added.\n",
      "Account G000000 Could Not be Added.\n",
      "Account J000000 Could Not be Added.\n",
      "Account S000000 Could Not be Added.\n",
      "Account T000000 Could Not be Added.\n",
      "Account X000000 Could Not be Added.\n",
      "Account Z000000 Could Not be Added.\n",
      "Account Z000000 Could Not be Added.\n",
      "Accounts Successfully Added to ashare!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for x in ACCOUNT_LIST:\n",
    "        sqlScriptShare = 'alter share {} add accounts={};'.format(shareName, x)\n",
    "        conn.cursor().execute(aSQLstatement)\n",
    "        try:\n",
    "            conn.cursor().execute(sqlScriptShare)\n",
    "        except:\n",
    "            print('Account {} Could Not be Added.'.format(x))\n",
    "    print(\"Accounts Successfully Added to {}!\".format(shareName))\n",
    "except:\n",
    "    print(\"There was an error in the alter share {} add accounts=... SQL.\".format(shareName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cda061d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-03T16:34:07.715800Z",
     "iopub.status.busy": "2021-08-03T16:34:07.715566Z",
     "iopub.status.idle": "2021-08-03T16:34:07.719413Z",
     "shell.execute_reply": "2021-08-03T16:34:07.718718Z",
     "shell.execute_reply.started": "2021-08-03T16:34:07.715776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to Snowflake has been closed.\n"
     ]
    }
   ],
   "source": [
    "conn.cursor().close()\n",
    "print(\"Connection to Snowflake has been closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07992763",
   "metadata": {},
   "source": [
    "## Check your Snowflake account to see if the Database & Table are created and filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b197e5d",
   "metadata": {},
   "source": [
    "## *IMPORTANT*: This only works with accounts that are from the same region and cloud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31087583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfca9907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Method\n",
    "# from snowflake.connector.pandas_tools import pd_writer\n",
    "\n",
    "\n",
    "# # Specify that the to_sql method should use the pd_writer function\n",
    "# # to write the data from the DataFrame to the table named \"customers\"\n",
    "# # in the Snowflake database.\n",
    "# dfTotal.to_sql('FORMATTED_REPORTS', conn, index=False, method=pd_writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
