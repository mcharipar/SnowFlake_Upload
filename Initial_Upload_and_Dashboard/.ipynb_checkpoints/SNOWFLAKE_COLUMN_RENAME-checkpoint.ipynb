{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbebcdc0",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<table>\n",
    "    <center>\n",
    "            <img src=\"https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/snowflake.png\">\n",
    "    </center>\n",
    "        <td>\n",
    "            <img src=\"..\\Images\\logo.jpg\" width=\"300\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"..\\Images\\call_center.jpg\" width=\"300\">\n",
    "        </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8cfe4",
   "metadata": {},
   "source": [
    "# Call Database to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ca81a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to pip the connector and install the dependencies:\n",
    "# https://docs.snowflake.com/en/user-guide/python-connector-install.html\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "f = open(\"..\\Login_Credentials\\SF_Account_Info.txt\", \"r\")\n",
    "\n",
    "usr = f.readline()\n",
    "usr = usr.replace('\\n', '')\n",
    "psswrd = f.readline()\n",
    "psswrd = psswrd.replace('\\n', '')\n",
    "accnt = f.readline()\n",
    "accnt = accnt.replace('\\n', '')\n",
    "dbName = f.readline()\n",
    "dbName = dbName.replace('\\n', '')\n",
    "path = f.readline()\n",
    "path = path.replace('\\n', '')\n",
    "file1 = f.readline()\n",
    "file1 = file1.replace('\\n', '')\n",
    "file2 = f.readline()\n",
    "file2 = file2.replace('\\n', '')\n",
    "file3 = f.readline()\n",
    "file3 = file3.replace('\\n', '')\n",
    "file4 = f.readline()\n",
    "file4 = file4.replace('\\n', '')\n",
    "file5 = f.readline()\n",
    "file5 = file5.replace('\\n', '')\n",
    "file6 = f.readline()\n",
    "file6 = file6.replace('\\n', '')\n",
    "file7 = f.readline()\n",
    "file7 = file7.replace('\\n', '')\n",
    "file8 = f.readline()\n",
    "file8 = file8.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69891ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCHARIPAR5 \n",
      " Victoria5! \n",
      " ob28888.east-us-2.azure \n",
      " ADBNAMEHERE \n",
      " J:\\\\Plan4Co\\SaturnCloud\\211-OC_Data\\ \n",
      " FormattedCallReports_year 2014.xlsx \n",
      " FormattedCallReports_year 2015.xlsx \n",
      " FormattedCallReports_year 2016.xlsx \n",
      " FormattedCallReports_year 2017.xlsx \n",
      " FormattedCallReports_year 2018.xlsx \n",
      " FormattedCallReports_year 2019.xlsx \n",
      " FormattedCallReports_year 2020.xlsx \n",
      " FormattedCallReports_year 2021.xlsx\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(usr,'\\n', psswrd,'\\n', accnt,'\\n', dbName, '\\n', \n",
    "          path, '\\n', file1,'\\n', file2,'\\n', file3, '\\n', \n",
    "          file4,'\\n', file5,'\\n', file6,'\\n', file7,'\\n', file8)\n",
    "except:\n",
    "    print('Check Login_Credentials/README.md for more info.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea8a88b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Following Share Will Be Created If It Does Not Exist: ashare\n",
      "The Following Accounts Will Be Granted Share Access:\n",
      "L000000 O000000 A000000 B000000 C000000 E000000 G000000 G000000 J000000 S000000 T000000 X000000 Z000000 Z000000 \n"
     ]
    }
   ],
   "source": [
    "f1 = open(\"..\\Login_Credentials\\SHARED_SF_Account_Info.txt\", \"r\")\n",
    "\n",
    "shareName = f1.readline()\n",
    "shareName = shareName.replace('\\n', '')\n",
    "\n",
    "sharedAccnt1 = f1.readline()\n",
    "sharedAccnt1 = sharedAccnt1.replace('\\n', '')\n",
    "sharedAccnt2 = f1.readline()\n",
    "sharedAccnt2 = sharedAccnt2.replace('\\n', '')\n",
    "sharedAccnt3 = f1.readline()\n",
    "sharedAccnt3 = sharedAccnt3.replace('\\n', '')\n",
    "sharedAccnt4 = f1.readline()\n",
    "sharedAccnt4 = sharedAccnt4.replace('\\n', '')\n",
    "sharedAccnt5 = f1.readline()\n",
    "sharedAccnt5 = sharedAccnt5.replace('\\n', '')\n",
    "sharedAccnt6 = f1.readline()\n",
    "sharedAccnt6 = sharedAccnt6.replace('\\n', '')\n",
    "sharedAccnt7 = f1.readline()\n",
    "sharedAccnt7 = sharedAccnt7.replace('\\n', '')\n",
    "sharedAccnt8 = f1.readline()\n",
    "sharedAccnt8 = sharedAccnt8.replace('\\n', '')\n",
    "sharedAccnt9 = f1.readline()\n",
    "sharedAccnt9 = sharedAccnt9.replace('\\n', '')\n",
    "sharedAccnt10 = f1.readline()\n",
    "sharedAccnt10 = sharedAccnt10.replace('\\n', '')\n",
    "sharedAccnt11 = f1.readline()\n",
    "sharedAccnt11 = sharedAccnt11.replace('\\n', '')\n",
    "sharedAccnt12 = f1.readline()\n",
    "sharedAccnt12 = sharedAccnt12.replace('\\n', '')\n",
    "sharedAccnt13 = f1.readline()\n",
    "sharedAccnt13 = sharedAccnt13.replace('\\n', '')\n",
    "sharedAccnt14 = f1.readline()\n",
    "sharedAccnt14 = sharedAccnt14.replace('\\n', '')\n",
    "sharedAccnt15 = f1.readline()\n",
    "sharedAccnt15 = sharedAccnt15.replace('\\n', '')\n",
    "\n",
    "try:\n",
    "    print(f'The Following Share Will Be Created If It Does Not Exist: {shareName}\\n' \n",
    "          + 'The Following Accounts Will Be Granted Share Access:\\n'\n",
    "          + sharedAccnt1, sharedAccnt2, sharedAccnt3, sharedAccnt4,\n",
    "          sharedAccnt5, sharedAccnt6, sharedAccnt7, sharedAccnt8, \n",
    "          sharedAccnt9, sharedAccnt10, sharedAccnt11, sharedAccnt12,\n",
    "          sharedAccnt13, sharedAccnt14, sharedAccnt15)\n",
    "except:\n",
    "    print('Check Login_Credentials/README.md for more info.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a46e9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accountList = [sharedAccnt1, sharedAccnt2, sharedAccnt3, sharedAccnt4, sharedAccnt5,\n",
    "               sharedAccnt6, sharedAccnt7, sharedAccnt8, sharedAccnt9, sharedAccnt10,\n",
    "               sharedAccnt11, sharedAccnt12, sharedAccnt13, sharedAccnt14, sharedAccnt15]\n",
    "ACCOUNT_LIST = []\n",
    "for i in accountList:\n",
    "    if len(i) != 0:\n",
    "        ACCOUNT_LIST.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90fd44fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "aSQLstatement = 'USE database {};'.format(dbName)\n",
    "sqlScript = 'create share {};'.format(shareName)\n",
    "sqlScript1 = 'grant usage on database {} to share {};'.format(dbName, shareName)\n",
    "sqlScript2 = 'grant usage on schema {}.public to share {};'.format(dbName, shareName)\n",
    "sqlScript3 = 'grant select on all tables in schema {}.public to share {};'.format(dbName, shareName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "163c1645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Snowflake using MCHARIPAR5 ob28888.east-us-2.azure\n"
     ]
    }
   ],
   "source": [
    "# Connect to SF\n",
    "conn = snowflake.connector.connect(\n",
    "    user=usr,\n",
    "    password=psswrd,\n",
    "    account=accnt,\n",
    "    role='ACCOUNTADMIN',\n",
    "    warehouse='COMPUTE_WH',\n",
    "    #database='<SOME_DATABASE>',\n",
    "    #table='<SOME_TABLE>',\n",
    "    #schema='PUBLIC'\n",
    "                                    )\n",
    "print(\"Connected to Snowflake using \" + usr + \" \" + accnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c10a0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tUsing files from dir J:\\\\Plan4Co\\SaturnCloud\\211-OC_Data\\\n"
     ]
    }
   ],
   "source": [
    "os.chdir(path)\n",
    "print(\"\\tUsing files from dir \" + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd067931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadExcel(fileName):\n",
    "    # Returns Year of File Passed to Method\n",
    "    def fileYear():\n",
    "        aYear = fileName[-7:-5]\n",
    "        return '20' + aYear\n",
    "    \n",
    "    # Creates String to Pass to SF Python Connector for Table Creation\n",
    "    def moreFormat(theInput):\n",
    "        \n",
    "        anthrList = []\n",
    "        stringList = []\n",
    "        o = 0\n",
    "        \n",
    "        for i in theInput:\n",
    "            if i.startswith(' '):\n",
    "                theInput[o] = i.strip()\n",
    "            o = o + 1\n",
    "            \n",
    "            if len(i) > 255:\n",
    "                i = i[:255]\n",
    "        \n",
    "            splChar = [\n",
    "            '(',')','[',']','/','\\\\','-','.',':','\\t','<','>','\"','?',\n",
    "            '!','`',\"'\",'&','^',' ','{','}','+','=','~','|',';','%','#']\n",
    "            for x in splChar:\n",
    "                i = i.replace(x, '_')\n",
    "            anthrList.append(i)\n",
    "            stringList.append(i)\n",
    "\n",
    "        stringList = str(stringList)\n",
    "        stringList = stringList.replace(\"'\", '\"')\n",
    "        stringList = stringList.replace(\",\", ' varchar,\\n')\n",
    "        stringList = stringList.strip(\"[]\")\n",
    "        stringList = stringList + \" varchar\"\n",
    "\n",
    "        return anthrList, stringList\n",
    "    \n",
    "    # Convert to Pandas DF\n",
    "    def makePandas():\n",
    "        if fileName != '':\n",
    "            dfSheet1 = pd.read_excel(fileName, sheet_name=0)\n",
    "            dfSheet2 = pd.read_excel(fileName, sheet_name=1)\n",
    "            dfSheet3 = pd.read_excel(fileName, sheet_name=2)\n",
    "            dfSheet1.convert_dtypes(), dfSheet2.convert_dtypes(), dfSheet3.convert_dtypes()\n",
    "            \n",
    "            # Call moreFormat to pass string to SF Python Connector & Change DF Column Names to Match\n",
    "            thisVar1 = dfSheet1.columns.tolist()\n",
    "            dfSheet1.columns, stringList1 = moreFormat(thisVar1)\n",
    "            thisVar2 = dfSheet2.columns.tolist()\n",
    "            dfSheet2.columns, stringList2 = moreFormat(thisVar2)\n",
    "            thisVar3 = dfSheet3.columns.tolist()\n",
    "            dfSheet3.columns, stringList3 = moreFormat(thisVar3)\n",
    "            \n",
    "            # Create Cursor Object\n",
    "            conn.cursor().execute(\"CREATE DATABASE IF NOT EXISTS {}\".format(dbName.upper()))\n",
    "            conn.cursor().execute(\"USE DATABASE {}\".format(dbName.upper()))\n",
    "            \n",
    "            # Create Snowflake Table and Columns & Upload the DF to SF\n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"NEEDSMETANDUNMET{}({})\".format(fileYear(), stringList1))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet1, 'NEEDSMETANDUNMET{}'.format(fileYear()))\n",
    "            \n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"CALLREPORTS{}({})\".format(fileYear(), stringList2))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet2, 'CALLREPORTS{}'.format(fileYear()))\n",
    "            \n",
    "            conn.cursor().execute(\n",
    "                \"CREATE OR REPLACE TABLE \"\n",
    "                \"REFERRALS{}({})\".format(fileYear(), stringList3))\n",
    "            success, nchunks, nrows, _ = write_pandas(conn, dfSheet3, 'REFERRALS{}'.format(fileYear()))            \n",
    "             \n",
    "            return print(fileName + ' Uploaded Succesfully To Snowflake!')\n",
    "        else:\n",
    "            return print('Nothing More to Upload.')\n",
    "    return makePandas()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f708cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2014.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2014.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file1 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b421e0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2015.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2015.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file2 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c4768d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2016.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2016.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file3 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f049f8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2017.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2017.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file4 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "490dc5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2018.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2018.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file5 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "463be2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2019.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2019.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file6 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ac7b70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2020.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2020.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file7 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9c58fe0-a5ad-4d09-9a2c-417d2b719db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading FormattedCallReports_year 2021.xlsx\n",
      "This will take several minutes.\n",
      "FormattedCallReports_year 2021.xlsx Uploaded Succesfully To Snowflake!\n"
     ]
    }
   ],
   "source": [
    "print(\"Uploading \" + file8 + \"\\nThis will take several minutes.\")\n",
    "uploadExcel(file8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb896153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Files Provided in SF_Account_Info.txt have been uploaded now.\n"
     ]
    }
   ],
   "source": [
    "print(\"All Files Provided in SF_Account_Info.txt have been uploaded now.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b09cc6-c9de-4a1a-8c1b-dbc8015825cc",
   "metadata": {},
   "source": [
    "## SQL to be Executed on Snowflake\n",
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f7f67e0-a519-4bc8-944f-d64d151fafe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# -- SPECIFICIES CORRECT SNOWFLAKE SETTINGS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript4 = 'USE role ACCOUNTADMIN;'\n",
    "sqlScript5 = 'USE warehouse COMPUTE_WH;'\n",
    "sqlScript6 = 'USE database \"{}\";'.format(dbName)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE AND ADDS ALL YEARS DATA TO IT\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"TOTAL_NEEDSMETANDUNMET\"\n",
    "sqlScript7 = 'CREATE TABLE \"TOTAL_NEEDSMETANDUNMET\" AS SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2014\";'\n",
    "sqlScript8 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2015\";'\n",
    "sqlScript9 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2016\";'\n",
    "sqlScript10 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2017\";'\n",
    "sqlScript11 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2018\";'\n",
    "sqlScript12 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2019\";'\n",
    "sqlScript13 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2020\";'\n",
    "sqlScript14 = 'INSERT INTO \"TOTAL_NEEDSMETANDUNMET\"(\"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\") SELECT \"DateOfCall\", \"CallReportNum\", \"TaxonomyCode\", \"TaxonomyName\", \"StateProvince\" FROM \"NEEDSMETANDUNMET2021\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE AND ADDS ALL YEARS DATA TO IT\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"ADBNAMEHERE\".\"PUBLIC\".\"TOTAL_CALLREPORTS\"\n",
    "sqlScript15 = 'CREATE TABLE \"TOTAL_CALLREPORTS\" AS SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2014\";'\n",
    "sqlScript16 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2015\";'\n",
    "sqlScript17 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2016\";'\n",
    "sqlScript18 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2017\";'\n",
    "sqlScript19 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2018\";'\n",
    "sqlScript20 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2019\";'\n",
    "sqlScript21 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2020\";'\n",
    "sqlScript22 = 'INSERT INTO \"TOTAL_CALLREPORTS\"(\"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\") SELECT \"CallReportNum\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"CALLREPORTS2021\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CREATES TABLE FROM TOTAL_* TABLES 13 COLUMNS TOTAL\n",
    "# ---------------------------------------------------------------------------\n",
    "# --DROP TABLE \"TOTAL_SATURNCLOUD\" \n",
    "sqlScript23 = 'CREATE TABLE \"TOTAL_SATURNCLOUD\" AS SELECT \"TOTAL_NEEDSMETANDUNMET\".\"DateOfCall\", \"TOTAL_NEEDSMETANDUNMET\".\"CallReportNum\", \"TOTAL_NEEDSMETANDUNMET\".\"TaxonomyCode\", \"TOTAL_NEEDSMETANDUNMET\".\"TaxonomyName\", \"TOTAL_NEEDSMETANDUNMET\".\"StateProvince\", \"TOTAL_CALLREPORTS\".\"Demographics___Gender__Person_in_Need_\", \"TOTAL_CALLREPORTS\".\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"ADBNAMEHERE\".\"PUBLIC\".\"TOTAL_NEEDSMETANDUNMET\" INNER JOIN \"TOTAL_CALLREPORTS\" ON \"TOTAL_NEEDSMETANDUNMET\".\"CallReportNum\"=\"TOTAL_CALLREPORTS\".\"CallReportNum\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL NON CA VALUES FROM STATEPROVINCE AND THEN DROPS THE COL\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript24 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"StateProvince\" IS NULL;'\n",
    "sqlScript25 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"StateProvince\"!=\\'CA\\';'\n",
    "sqlScript26 = 'ALTER TABLE \"TOTAL_SATURNCLOUD\" DROP COLUMN \"StateProvince\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL REMAINING NULL VALUES FROM THE REST OF THE COLUMNS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript27 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"Demographics___Gender__Person_in_Need_\" IS NULL;'\n",
    "sqlScript28 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" IS NULL;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL DUPLICATE ROWS WITH SAME CALLREPORTNUM AND TAXONOMY CODE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript29 = 'DELETE FROM \"TOTAL_SATURNCLOUD\" WHERE \"TaxonomyCode\" NOT LIKE \\'R%\\';'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- REMOVE ALL DUPLICATE ROWS WITH SAME CALLREPORTNUM AND TAXONOMY CODE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript30 = 'CREATE OR REPLACE TABLE \"TOTAL_SATURNCLOUD\" AS SELECT DISTINCT * FROM \"TOTAL_SATURNCLOUD\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CONSOLIDATE TAXONOMY CODES WITH * TAG\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript31 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"TaxonomyCode\" = LEFT(\"TaxonomyCode\", CHARINDEX(\\'*\\', \"TaxonomyCode\") - 2) WHERE CHARINDEX(\\'*\\', \"TaxonomyCode\") > 0;'\n",
    "sqlScript32 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"TaxonomyName\" = LEFT(\"TaxonomyName\", CHARINDEX(\\'*\\', \"TaxonomyName\") - 2) WHERE CHARINDEX(\\'*\\', \"TaxonomyName\") > 0;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- FORMAT DATEOFCALL TRUNCATE TIME\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript33 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"DateOfCall\" = LEFT(\"DateOfCall\", CHARINDEX(\\' \\', \"DateOfCall\") - 1) WHERE CHARINDEX(\\' \\', \"DateOfCall\") > 0;'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- Demographics_Prior_or_Current_U_S_Military_Service_Person...\n",
    "# -- CHANGE ALL NON YES RESPONSES TO NO\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript34 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Unknown\\', \\'No\\');'\n",
    "sqlScript35 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Not Asked\\', \\'No\\');'\n",
    "sqlScript36 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\"=REPLACE(\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\", \\'Declined to Answer\\', \\'No\\');'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- Demographics_Gender_Person_in_Need CHANGE NOT ASKED, TRANS, AND\n",
    "# -- DECLINED TO ANSWER TO OTHER/UNKNOWN/CANNOT DETERMINE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript37 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Not Asked\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript38 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Declined to Answer\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript39 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Trans\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "sqlScript40 = 'UPDATE \"TOTAL_SATURNCLOUD\" SET \"Demographics___Gender__Person_in_Need_\"=REPLACE(\"Demographics___Gender__Person_in_Need_\", \\'Client is person in need (not applicable)\\', \\'Other/Unknown/Cannot determine\\');'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- COUNT CALLREPORT BY DATEOFCALL AND TAXONOMYNAME AND DEMOGRAPHICS\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript41 = 'CREATE OR REPLACE TABLE \\\"TOTAL_SATURNCLOUD\\\" AS SELECT \\\"DateOfCall\\\", \\\"TaxonomyCode\\\", \\\"TaxonomyName\\\", \\\"Demographics___Gender__Person_in_Need_\\\", \\\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\\\", COUNT(*) AS \\\"NumberOfCalls\\\" FROM \\\"TOTAL_SATURNCLOUD\\\" GROUP BY \\\"DateOfCall\\\", \\\"TaxonomyCode\\\", \\\"TaxonomyName\\\", \\\"Demographics___Gender__Person_in_Need_\\\", \\\"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\\\";'\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# -- CHANGE DATEOFCALL DATATYPE TO DATE\n",
    "# ---------------------------------------------------------------------------\n",
    "sqlScript42 = 'ALTER TABLE \"TOTAL_SATURNCLOUD\" ADD \\\"DATE\\\" DATE;'\n",
    "sqlScript43 = 'CREATE OR REPLACE TABLE \"TOTAL_SATURNCLOUD\" AS(SELECT to_date(\"DateOfCall\") date,\"NumberOfCalls\", \"TaxonomyCode\", \"TaxonomyName\", \"Demographics___Gender__Person_in_Need_\", \"Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_\" FROM \"TOTAL_SATURNCLOUD\");'\n",
    "sqlScript44 = 'alter table \"TOTAL_SATURNCLOUD\" rename column \"DATE\" to \"DateOfCall\";'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcdc745a-5a71-4a8e-8766-dc4229828d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlList = [sqlScript4 ,sqlScript5, sqlScript6, sqlScript7, \n",
    "           sqlScript8, sqlScript9 ,sqlScript10 ,sqlScript11 ,\n",
    "           sqlScript12 ,sqlScript13, sqlScript14, sqlScript15,\n",
    "           sqlScript16, sqlScript16 ,sqlScript17 ,sqlScript18 ,\n",
    "           sqlScript19 ,sqlScript20, sqlScript21, sqlScript22,\n",
    "           sqlScript23, sqlScript24 ,sqlScript25 ,sqlScript25 ,\n",
    "           sqlScript26 ,sqlScript27, sqlScript28, sqlScript29,\n",
    "           sqlScript30, sqlScript31 ,sqlScript32 ,sqlScript33 ,\n",
    "           sqlScript34 ,sqlScript35, sqlScript36, sqlScript37,\n",
    "           sqlScript38, sqlScript39 ,sqlScript40 ,sqlScript41 ,\n",
    "           sqlScript42 ,sqlScript43, sqlScript44]\n",
    "# sqlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d708d448-b96d-447f-ab6d-a4f1a970ab40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Completed\n"
     ]
    }
   ],
   "source": [
    "for u in sqlList:\n",
    "    try:\n",
    "        conn.cursor().execute(u)\n",
    "    except: \n",
    "        print(f'This SQL Query Could Not Be Executed:\\n{u}')\n",
    "        \n",
    "print('Preprocessing Completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6adb97-d684-4e5d-bcb0-eec1856bfea7",
   "metadata": {},
   "source": [
    "# Predictive Modeling & Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4178c7d3-9c1b-467a-b6b1-b520d3234ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install --upgrade tensorflow\n",
    "# !pip install --user --upgrade tensorflow-probability\n",
    "\n",
    "# !pip install -U numpy==1.18.5\n",
    "# !pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a36fc589-1dda-43bd-a142-3d418b5f66ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the libraries\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d209ff-3710-4e84-a4ca-ac5273d95964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake Setup Complete\n"
     ]
    }
   ],
   "source": [
    "for t in sqlList[:3]:\n",
    "    try:\n",
    "        conn.cursor().execute(t)\n",
    "    except: \n",
    "        print(f'This SQL Query Could Not Be Executed:\\n{t}')\n",
    "        \n",
    "print('Snowflake Setup Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a79ac0-5b3b-457d-804d-314e19ff569a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "002003 (42S02): SQL compilation error:\nObject 'TOTAL_SATURNCLOUD' does not exist or not authorized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d540a562b488>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcurr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'SELECT * FROM TOTAL_SATURNCLOUD'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcurr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_pandas_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\snowflake\\connector\\cursor.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, command, params, _bind_stage, timeout, _exec_async, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _use_ijson, _is_put_get, _raise_put_get_error, _force_put_overwrite, file_stream)\u001b[0m\n\u001b[0;32m    719\u001b[0m                 \u001b[1;34m\"sfqid\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sfqid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m             }\n\u001b[1;32m--> 721\u001b[1;33m             Error.errorhandler_wrapper(\n\u001b[0m\u001b[0;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mProgrammingError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\snowflake\\connector\\errors.py\u001b[0m in \u001b[0;36merrorhandler_wrapper\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcursor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrorhandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mconnection\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\snowflake\\connector\\errors.py\u001b[0m in \u001b[0;36mdefault_errorhandler\u001b[1;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mSnowflake\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \"\"\"\n\u001b[1;32m--> 188\u001b[1;33m         raise error_class(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mmsg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"msg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0merrno\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merror_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errno\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: 002003 (42S02): SQL compilation error:\nObject 'TOTAL_SATURNCLOUD' does not exist or not authorized."
     ]
    }
   ],
   "source": [
    "# Creates dataframe frome Snowflake SQL Table\n",
    "curr = conn.cursor()\n",
    "sql = 'SELECT * FROM TOTAL_SATURNCLOUD'\n",
    "curr.execute(sql)\n",
    "\n",
    "df = curr.fetch_pandas_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c933a16-9bda-4549-9261-c37fb7fbd2c5",
   "metadata": {},
   "source": [
    "### Renaming and dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43514c0f-4844-49ef-865c-4428c1de1d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'TaxonomyCode':'Level5Code',\n",
    "'Demographics___Gender__Person_in_Need_':'Gender',\n",
    "'Demographics___Prior_or_Current_U_S__Military_Service__Person_in_Needs_Household_':'Militants'},inplace=True)\n",
    "\n",
    "df['Level2Code'] = df['Level5Code'].str.extract('(R.)', expand=True)\n",
    "\n",
    "df = df.drop(columns  = ['Level5Code','TaxonomyName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3912d11-6b85-493d-b704-3ffa32c686f8",
   "metadata": {},
   "source": [
    "### Encoding Militants Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dd3ed0b-1f93-4baf-96f0-c0e83cc9c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "## Militants - Categorical to Numerical\n",
    "taxonomy_encoded = le.fit_transform(df['Militants'])\n",
    "df['Militants'] = taxonomy_encoded\n",
    "\n",
    "df3 = pd.get_dummies(df,columns=['Level2Code','Gender'])\n",
    "\n",
    "df3 = df3.groupby(df3['DateOfCall'], as_index=False, sort=True).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd3f85e-c003-44cd-904e-f355e625d37c",
   "metadata": {},
   "source": [
    "### Basic number of unqiue values assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5253b06d-6f70-44bf-aff9-53dc142cb8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "genderList = df['Gender'].unique()\n",
    "# for i in genderList:\n",
    "#     print(\"Number of \" + i + \" :\"+ str(len(df[df['Gender'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de71404b-dda4-41f8-b36c-81adc4976167",
   "metadata": {},
   "outputs": [],
   "source": [
    "MilitantList = df['Militants'].unique()\n",
    "# for i in MilitantList:\n",
    "#     print(\"Number \" + str(i) + \" :\" + str(len(df[df['Militants'] == i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c93d7291-0281-4722-abe8-629fd1f74930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9570f60c-bd55-473d-87b6-cb51011168f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe all the data\n",
    "# df3.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d21853bd-5093-4eb7-b82c-bd405207cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize missing by column\n",
    "# df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9bc71ac-9a93-47b7-b247-6d0deb1c2b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separate dates for future plotting\n",
    "train_dates = pd.to_datetime(df3['DateOfCall'])\n",
    "\n",
    "## Variables for training\n",
    "df4 = df3.iloc[:, 1:11].astype(float)\n",
    "#df4.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b98aa73-6974-407f-b63b-b22622258ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(df4)\n",
    "df4_scaled = scaler.transform(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d92dfd15-b792-4bbe-b182-6a6893e48814",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up a training/validation/testing dataset\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "n_future = 1 # Number of days we want to predict into the future\n",
    "n_past = 14 # Number of past days we want to use to predict the future\n",
    "\n",
    "for i in range (n_past, len(df4_scaled) - n_future +1):\n",
    "    X_train.append(df4_scaled[i - n_past:i, 0:df4.shape[1]])\n",
    "    y_train.append(df4_scaled[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "## Convert to numpy arrays\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a804524-a73a-4241-a7fd-1d4dbc30505a",
   "metadata": {},
   "source": [
    "## Build a LSTM complex model with dropout, add L1 regularization, smaller weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5545a060-1068-4aff-adac-8fb80732dd56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (lstm/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-abab81c9b610>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# fit this model/architecture to my data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mhistory5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m history5.fit(X_train,\n\u001b[0;32m     37\u001b[0m           \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-abab81c9b610>\u001b[0m in \u001b[0;36mbuild_model5\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mbuild_model5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     model.add(LSTM(64,\n\u001b[0m\u001b[0;32m      8\u001b[0m                    \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                    \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ml1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml1_penalty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    206\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 660\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    946\u001b[0m                                                 input_list)\n\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1081\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1082\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1083\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1084\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    814\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    854\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m   1137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 860\u001b[1;33m       \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m       init_state = get_initial_state_fn(\n\u001b[0m\u001b[0;32m    643\u001b[0m           inputs=None, batch_size=batch_size, dtype=dtype)\n\u001b[0;32m    644\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[1;34m(self, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2507\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_initial_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m     return list(_generate_zero_filled_state_for_cell(\n\u001b[0m\u001b[0;32m   2509\u001b[0m         self, inputs, batch_size, dtype))\n\u001b[0;32m   2510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state_for_cell\u001b[1;34m(cell, inputs, batch_size, dtype)\u001b[0m\n\u001b[0;32m   2988\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2989\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2990\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_generate_zero_filled_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m_generate_zero_filled_state\u001b[1;34m(batch_size_tensor, state_size, dtype)\u001b[0m\n\u001b[0;32m   3004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3005\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3006\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3007\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3008\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 867\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36mcreate_zeros\u001b[1;34m(unnested_state_size)\u001b[0m\n\u001b[0;32m   3001\u001b[0m     \u001b[0mflat_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munnested_state_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3002\u001b[0m     \u001b[0minit_state_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_size_tensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mflat_dims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3003\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_state_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3005\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_nested\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2911\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2912\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_zeros_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[1;34m(shape, dtype, name)\u001b[0m\n\u001b[0;32m   2958\u001b[0m           \u001b[1;31m# Create a constant if it won't be very big. Otherwise create a fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m           \u001b[1;31m# op to prevent serialized GraphDefs from becoming too large.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2960\u001b[1;33m           \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2961\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2962\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_constant_if_small\u001b[1;34m(value, shape, dtype, name)\u001b[0m\n\u001b[0;32m   2894\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_if_small\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2895\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2896\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2897\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3050\u001b[0m     \"\"\"\n\u001b[1;32m-> 3051\u001b[1;33m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0m\u001b[0;32m   3052\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   3053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m     raise NotImplementedError(\n\u001b[0m\u001b[0;32m    868\u001b[0m         \u001b[1;34m\"Cannot convert a symbolic Tensor ({}) to a numpy array.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;34m\" This error may indicate that you're trying to pass a Tensor to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (lstm/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.regularizers import l1\n",
    "l1_penalty = 0.001\n",
    "\n",
    "# build a two layer neural network with regularization\n",
    "def build_model5():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   input_shape = (X_train.shape[1], X_train.shape[2]),\n",
    "                   return_sequences = True))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(64,\n",
    "                   activation = 'relu',\n",
    "                   kernel_regularizer=l1(l1_penalty),\n",
    "                   return_sequences = False))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y_train.shape[1]))\n",
    "    \n",
    "    model.compile(optimizer = 'adam',\n",
    "                  loss = 'mse',\n",
    "                  metrics = ['mae'])\n",
    "    return model\n",
    "\n",
    "# fit this model/architecture to my data\n",
    "history5 = build_model5()\n",
    "history5.fit(X_train,\n",
    "          y_train,\n",
    "          epochs = 500,\n",
    "          batch_size = 32,\n",
    "          validation_split = 0.2,\n",
    "          verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4033bc97-54a2-4b1f-8821-101681faa0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize model\n",
    "# history5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc394b5f-1918-4354-9ec9-bc90843efe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss function per epoch\n",
    "# plt.plot(history5.history.history['loss'],\n",
    "#          color='red')\n",
    "# plt.plot(history5.history.history['val_loss'],\n",
    "#          color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d8ec46-615e-4f78-ac11-e2afbe09355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss function per epoch\n",
    "# plt.plot(history5.history.history['mae'],\n",
    "#          color='red')\n",
    "# plt.plot(history5.history.history['val_mae'],\n",
    "#          color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ef03f-cbcf-4f91-821e-91c359a80565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The min validation loss of',\n",
    "#       np.min(history5.history.history['val_loss']),\n",
    "#       ',\\n was at epoch',\n",
    "#       np.argmin(history5.history.history['val_loss']))\n",
    "\n",
    "# print('The min validation mae of',\n",
    "#       np.min(history5.history.history['val_mae']),\n",
    "#       ',\\n was at epoch',\n",
    "#       np.argmin(history5.history.history['val_mae']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f161c4c9-e404-4882-98fa-e1dde7973949",
   "metadata": {},
   "source": [
    "## Forecasting Future Number Of Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b2261-95b6-438b-97ee-dbc253206ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin with the last day in training and forcast future\n",
    "future_ndays = 30\n",
    "forecast_period_dates = pd.date_range(list(train_dates)[-1], \n",
    "                                      periods = future_ndays, \n",
    "                                      freq = '1d').tolist()\n",
    "\n",
    "## forecast\n",
    "forecast = history5.predict(X_train[-future_ndays:])\n",
    "\n",
    "## Perform inverse transformation to rescale back to original range\n",
    "forecast_copies = np.repeat(forecast, \n",
    "                            df4.shape[1], \n",
    "                            axis = -1)\n",
    "y_pred_future = scaler.inverse_transform(forecast_copies)[:, 0]\n",
    "\n",
    "## Convert forecast timestamp to date\n",
    "forecast_dates = []\n",
    "for time_i in forecast_period_dates:\n",
    "    forecast_dates.append(time_i.date())\n",
    "\n",
    "df_forecast = pd.DataFrame({'DateOfCall': np.array(forecast_dates), \n",
    "                            'Forecast NumberOfCalls':y_pred_future})\n",
    "df_forecast['DateOfCall'] = pd.to_datetime(df_forecast['DateOfCall'])\n",
    "\n",
    "#df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4faa6f-e75c-4be9-95f1-cd651fdb0178",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original = df3[['DateOfCall', 'NumberOfCalls']]\n",
    "Original['DateOfCall'] = pd.to_datetime(Original['DateOfCall'])\n",
    "Original = Original.loc[Original['DateOfCall'] >= '2021-01-01']\n",
    "\n",
    "## Plot Observed and forecast\n",
    "# sns.lineplot(Original['DateOfCall'], Original['NumberOfCalls'])\n",
    "# sns.lineplot(df_forecast['DateOfCall'], df_forecast['Forecast NumberOfCalls'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056644dd-a5b4-4222-be15-4b91bb3cd3f9",
   "metadata": {},
   "source": [
    "### Upload Predictions to Table In Same Snowflake Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5514f71-c7a3-4f90-b637-18e9d13fd61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures Column Names are in the Correct Format for Snowflake\n",
    "def moreFormat(theInput):\n",
    "        \n",
    "        anthrList = []\n",
    "        stringList = []\n",
    "        o = 0\n",
    "        \n",
    "        for i in theInput:\n",
    "            if i.startswith(' '):\n",
    "                theInput[o] = i.strip()\n",
    "            o = o + 1\n",
    "            \n",
    "            if len(i) > 255:\n",
    "                i = i[:255]\n",
    "        \n",
    "            splChar = [\n",
    "            '(',')','[',']','/','\\\\','-','.',':','\\t','<','>','\"','?',\n",
    "            '!','`',\"'\",'&','^',' ','{','}','+','=','~','|',';','%','#']\n",
    "            for x in splChar:\n",
    "                i = i.replace(x, '_')\n",
    "            anthrList.append(i)\n",
    "            stringList.append(i)\n",
    "\n",
    "        stringList = str(stringList)\n",
    "        stringList = stringList.replace(\"'\", '\"')\n",
    "        stringList = stringList.replace(\",\", ' varchar,\\n')\n",
    "        stringList = stringList.strip(\"[]\")\n",
    "        stringList = stringList + \" varchar\"\n",
    "\n",
    "        return anthrList, stringList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dacca8-b1b1-4c3c-b0e3-6dec4896c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast.convert_dtypes()\n",
    "thisVar1 = df_forecast.columns.tolist()\n",
    "df_forecast.columns, stringList1 = moreFormat(thisVar1)\n",
    "\n",
    "# Snowflake not accepting pandas datetime datatype correctly\n",
    "df_forecast['DateOfCall'] = df_forecast['DateOfCall'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c63a1-42d6-474f-82b8-91856f6a3bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_forecast.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d395351-6538-4aab-a4ca-38e2839c0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL for Table Column Names and Datatypes\n",
    "stringList1 = '\"DateOfCall\" VARCHAR, \"Forecast_NumberOfCalls\" FLOAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93693c9-1db3-462f-958b-d7bdc251646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.cursor().execute(\"USE DATABASE {}\".format(dbName.upper()))\n",
    "            \n",
    "# Create Snowflake Table and Columns & Upload the DF to SF\n",
    "conn.cursor().execute(\n",
    "    \"CREATE OR REPLACE TABLE \"\n",
    "    \"TOTAL_SATURNCLOUD_PREDICTIONS({})\".format(stringList1))\n",
    "success, nchunks, nrows, _ = write_pandas(conn, df_forecast, 'TOTAL_SATURNCLOUD_PREDICTIONS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9bc1d3-1995-4aae-9961-cb2c55acdd70",
   "metadata": {},
   "source": [
    "#### Changes VARCHAR to DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f94015a-a3d8-44e8-a922-da37b88cac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.cursor().execute('ALTER TABLE \"TOTAL_SATURNCLOUD_PREDICTIONS\" ADD \"DATE\" DATE;')\n",
    "\n",
    "\n",
    "conn.cursor().execute(\n",
    "    'CREATE OR REPLACE TABLE \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\" AS(SELECT to_date(\\\"DateOfCall\\\") date,\\\"Forecast_NumberOfCalls\\\"FROM \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\");')\n",
    "\n",
    "conn.cursor().execute('alter table \\\"TOTAL_SATURNCLOUD_PREDICTIONS\\\" rename column \\\"DATE\\\" to \\\"DateOfCall\\\";')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4936fe0c-6deb-4088-88d2-581e8b02257c",
   "metadata": {},
   "source": [
    "## Sets Up Shares on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b16f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn.cursor().execute(aSQLstatement)\n",
    "    conn.cursor().execute(sqlScript)\n",
    "    print('Share Created!')\n",
    "except:\n",
    "    print(\"This share already esixts in your Snowflake account.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f03fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    conn.cursor().execute(aSQLstatement)\n",
    "    conn.cursor().execute(sqlScript1)\n",
    "    conn.cursor().execute(sqlScript2)\n",
    "    conn.cursor().execute(sqlScript3)\n",
    "except:\n",
    "    print(\"There was an error in the grant usage on... SQL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e55a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for x in ACCOUNT_LIST:\n",
    "        sqlScriptShare = 'alter share {} add accounts={};'.format(shareName, x)\n",
    "        conn.cursor().execute(aSQLstatement)\n",
    "        try:\n",
    "            conn.cursor().execute(sqlScriptShare)\n",
    "        except:\n",
    "            print('Account {} Could Not be Added.'.format(x))\n",
    "    print(\"Accounts Successfully Added to {}!\".format(shareName))\n",
    "except:\n",
    "    print(\"There was an error in the alter share {} add accounts=... SQL.\".format(shareName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe83e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.cursor().close()\n",
    "print(\"Connection to Snowflake has been closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdc654e",
   "metadata": {},
   "source": [
    "## Check your Snowflake account to see if the Database & Table are created and filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88f6630",
   "metadata": {},
   "source": [
    "## *IMPORTANT*: This only works with accounts that are from the same region and cloud!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c8b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16c0c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Method\n",
    "# from snowflake.connector.pandas_tools import pd_writer\n",
    "\n",
    "\n",
    "# # Specify that the to_sql method should use the pd_writer function\n",
    "# # to write the data from the DataFrame to the table named \"customers\"\n",
    "# # in the Snowflake database.\n",
    "# dfTotal.to_sql('FORMATTED_REPORTS', conn, index=False, method=pd_writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
